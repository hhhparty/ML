{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 聚类\n",
    "\n",
    "\n",
    ">以下内容参考了周志华《机器学习》 清华大学出版社 2016.\n",
    "\n",
    "在无监督学习（unsupervised learning）中，训练样本的的标记信息是未知的。\n",
    "\n",
    "无监督学习的目标是通过对无标记训练样本的学习来揭示数据的内在性质及规律，为进一步的数据分析提供基础。\n",
    "\n",
    "此类学习任务中研究最多、应用最广的是聚类（clustering）。\n",
    "\n",
    "![聚类示例](images/clustering/clusteringdemo.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 聚类任务\n",
    "\n",
    "聚类算法试图将数据集中的样本，划分为若干个通常是不相交的子集，每个子集称为一个“簇”（cluster）。\n",
    "\n",
    "划分后，每个簇可能对应某个潜在的概念/类别，以西瓜为例：“本地瓜”、“外地瓜”等。\n",
    "\n",
    "**需要注意：这些概念事先是未知的，聚类过程仅能够自动形成簇结构，簇所对应的概念语义需由使用者（聚类算法之外的程序或人）来把握和命名。**\n",
    "\n",
    "\n",
    "形式化表示：\n",
    "\n",
    "假定样本集 $D={x_1,x_2,...,x_m}$ 包含m个无标记样本，每个样本 $x_i = (x_{i1},x_{i2},...,x_{im}) $ 是一个n维特征向量，则聚类算法将样本集D划分为k个不相交地簇 $ \\{C_l | l = 1,2,...,k \\}$ ，其中 $ C_{l'} \\cap _{l'\\neq _l }C_l = \\emptyset $ 且 $D= \\cup ^k _{l=1} C_l $ 。\n",
    "\n",
    "相应地，我们用 $\\lambda_j \\in {1,2,...,k} $ 表示样本$x_j$的“簇标记”（cluster label），即$x_j \\in C_{\\lambda_j}$。\n",
    "\n",
    "于是，聚类的结果可用包含m个元素的簇标记向量$\\lambda = (\\lambda_1;\\lambda_2;...;\\lambda_m)$表示。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 聚类的应用意义\n",
    "\n",
    "聚类即能作为一个单独过程，用于寻找数据的潜在分布结构，也可以作为分类等其他学习任务的前驱过程。\n",
    "\n",
    "例如，在一些商业应用中需要对新用户的类型进行判别（用户画像），但定义“用户类型”对商家来说却不太容易，这时可以借助聚类工具对用户数据进行分析，根据聚类结果将每个簇定义为一个类，然后再基于这些类训练分类模型，用于判别新用户的类型。\n",
    "\n",
    "![用户画像的要素](images/clustering/用户画像的要素.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 用户画像\n",
    "\n",
    "- Step1：准确识别用户\n",
    "  + 用户识别的目的是为了区分用户、单点定位；\n",
    "  + 用户识别的方式有很多种，如cookie、注册ID、邮箱、微信/微博/QQ等第三方登录、手机号等；\n",
    "  + 手机号是目前移动端最为准确的用户标识；\n",
    "  + **微博/微信/QQ等第三方登录成企业识别用户的折中选择。**\n",
    "  \n",
    "- Step2：动态跟踪用户行为轨迹\n",
    "  + 动态行为数据可以确认用户不同场景下的不同访问轨迹，助力广告主跨端控频营销。\n",
    "  + 用户网络行为动态跟踪主要包括三个维度：**场景+媒体+路径**\n",
    "  + 应用到互联网中，场景主要包括访问设备、访问时段；\n",
    "  + 媒体指某一时段下用户具体访问的媒体，如资讯类、视频类、游戏类、社交类等；\n",
    "  + 路径指用户进入和离开某媒体的路径，可以简单理解为用户的站内与站外行为，如是通过搜索导航进入还是直接打开该APP，离开时是站内跳转到其他网页还是直接关闭。\n",
    "  + 一方面有助于媒体自身优化流量运营，另一方面帮助广告主有效控制不同页面的投放频次，避免产生用户倦怠。\n",
    "  \n",
    "- Step3：结合静态数据评估用户价值\n",
    "  + 静态数据获取后，需要对人群进行因子和聚类分析；\n",
    "  + 不同的目的分类依据不同：\n",
    "    + 如对于产品设计来说，按照使用动机或使用行为划分是最为常见的方式；\n",
    "    + 而对于营销类媒体来说，依据消费形态来区分人群是最为直接的分类方式。\n",
    "  + **静态数据主要包括用户的人口属性、商业属性、消费特征、生活形态、CRM五大维度。**\n",
    "    + 其获取方式存在多种，数据挖掘是最为常见也是较为精准的一种方式；\n",
    "    + 如果数据有限，则需要定性与定量结合补充，定性方法如小组座谈会、用户深访、日志法、Laddering 阶梯法、透射法等；\n",
    "    + 主要是通过开放性的问题潜入用户真实的心理需求，具象用户特征。\n",
    "    + 定量更多是通过定量问卷调研的方式进行，关键在于后期定量数据的建模与分析，目的是通过封闭性问题一方面对定性假设进行验证，另一方面获取市场的用户分布规律。\n",
    "    \n",
    "- Step4：用户标签定义与权重\n",
    "  + 根据特征值对群体进行定义，有助于广告主一目了然掌握该群体的特性。\n",
    "  + 一个群体会有多个标签，不同的群体之间也会有标签的重合，此时标签的权重反映了不同群体的核心特征。\n",
    "  + 通常，一个好的用户画像，不同人群之间的标签重合度较小，只有在那些权重较小的标签上会有些许重合。\n",
    "  + **需要从繁杂的数据中抽取共同的特征值**\n",
    "\n",
    "- Step5：不同人群优先级排列\n",
    "  + **根据企业自身情况排列不同组合。**\n",
    "  + 大部分画像只完成上述4步就结束了，然而最后一步决定了最终效果的落地。\n",
    "  + 对于广告主来说可以理解为媒介的组合策略。组合策略可以按照频率的高低、市场的大小、收益的潜力、竞争优势等，根据企业自身情况排列不同组合。\n",
    "  + 例如：品牌刚刚建立，需要快速提升知名度，可以按照不同媒体目标人群覆盖率的高低进行预算分配；当品牌具备一定知名度，企业核心领域营收处于快速增长期时，可以按照不同媒体目标人群贡献的市场大小进行分配；当企业想开拓新市场时，可以按照不同媒体目标人群的收益潜力进行分配，另外如企业品牌需增强差异化的竞争优势时，可按照不同媒体目标人群的竞争优势进行投放。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 用户画像示例\n",
    "![用户画像示例](images/clustering/用户画像示例.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "基于不同的学习策略，有多种不同的聚类算法。下面先考虑算法涉及的两个基本问题：性能度量和距离计算。\n",
    "\n",
    "## 聚类算法的性能度量\n",
    "\n",
    "聚类性能度量亦称为聚类“有效性指标”（validity index）。\n",
    "\n",
    "与监督学习中的性能度量作用相似，对聚类结果，我们需要通过某种性能来度量或评估其好坏。\n",
    "\n",
    "另一方面，若明确了最终将要使用的性能度量，则可直接将其作为聚类过程的优化目标，从而更好地得到符合要求的聚类结果。\n",
    "\n",
    "聚类是将样本集D划分维若干互不相交的子集，即样本簇。那么，什么样的聚类结果比较好呢？\n",
    "\n",
    "直观上看，我们希望“物以类聚”，即同一簇的样本尽可能彼此相似，不同簇尽可能不同。\n",
    "\n",
    "即“簇内相似度”（intra-cluster similarity）高，而“蔟间相似度”（inter-cluster similarity）低。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 聚类性能度量类型\n",
    "\n",
    "度量类型常见地有两类：\n",
    "\n",
    "- 第一种：将聚类结果与某个“参考模型”（reference model）进行比较，称为“外部指标”（external index）；\n",
    "- 第二种：直接考察聚类结果，而不利用任何参考模型，称为“内部指标”（internal index）。\n",
    "\n",
    "对数据集 $D=\\{x_1,x_2,...,x_m\\}$，假定通过聚类给出的簇，划分为 $ C=\\{C_1,C_2,...,C_k\\}$，参考模型给出的簇划分为 $ C^*=\\{C_1^*,C_2^*,...,C_s^*\\}$。\n",
    "\n",
    "相应地，令$\\lambda$与$\\lambda^*$分别表示与$ C$和$ C^*$对应的簇标记向量。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "我们将样本两两配对考虑，定义：\n",
    "\n",
    "$a = |SS|, SS = \\{ (x_i,x_j)  |  \\lambda_i = \\lambda_j ,\\lambda_i^* = \\lambda_j^*,i<j \\},$   —— 式（1）\n",
    "\n",
    "$b = |SD|, SD = \\{ (x_i,x_j) | \\lambda_i = \\lambda_j ,\\lambda_i^* \\neq \\lambda_j^*,i<j \\},$   —— 式（2）\n",
    "\n",
    "$c = |DS|, DS = \\{ (x_i,x_j) | \\lambda_i \\neq \\lambda_j ,\\lambda_i^* = \\lambda_j^*,i<j \\},$   —— 式（3）\n",
    "\n",
    "$d = |DD|, DD = \\{ (x_i,x_j) | \\lambda_i \\neq \\lambda_j ,\\lambda_i^* \\neq \\lambda_j^*,i<j \\},$   —— 式（4）\n",
    "\n",
    "其中：\n",
    "- 集合SS包含了在C中隶属于相同簇,且在$C^*$中也隶属于相同簇的样本对；\n",
    "- 集合SD包含了在C中隶属于相同簇,但在$C^*$中不隶属于相同簇的样本对；\n",
    "- 集合DS包含了在C中不隶属于相同簇,但在$C^*$中隶属于相同簇的样本对；\n",
    "- 集合DD包含了在C中不隶属于相同簇,且在$C^*$中不隶属于相同簇的样本对；\n",
    "\n",
    "由于每个样本对$(x_i,x_j) ,（i<j）$，仅能出现在上面某一个集合中，因此有$a+b+c+d = m(m-1)/2$成立。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 聚类性能度量的外部指标\n",
    "\n",
    "基于上面的（1）到（4）式，可以推导出下面这些常用的聚类性能度量外部指标：\n",
    "\n",
    "- Jaccard系数（Jaccard Coefficient，简称JC)\n",
    "\n",
    "> $JC = \\frac{a}{a+b+c}$   —— 式(5)\n",
    "\n",
    "- FM指数（Fowlkes and mallows Index，简称FMI)\n",
    "\n",
    "> $FMI = \\sqrt{\\frac{a}{a+b}\\cdot \\frac{a}{a+c}}$   —— 式(6)\n",
    "\n",
    "- Rand指数（Rand Index，简称RI)\n",
    "\n",
    "> $RI = \\frac{2(a+d)}{m(m-1)}$   —— 式（7）\n",
    "\n",
    "显然，上述性能度量的结果值均在[0,1]区间，值越大越好。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 聚类性能度量的内部指标\n",
    "\n",
    "考虑聚类结果的簇划分 $C=\\{C_1,C_2,...,C_k\\}$，定义：\n",
    "\n",
    "> 簇C内样本间的平均距离： $avg(C) = \\frac{2}{|C|(|C|-1)} \\sum_{1\\leq i<j\\leq|C|}dist(x_i,x_j)$   —— 式(8)\n",
    "\n",
    "> 簇C内样本间的最远距离：$diam(C) = max_{1\\leq i<j\\leq|C|}dist(x_i,x_j)$  —— 式(9)\n",
    "\n",
    "> 簇$C_i$与簇$C_j$最近样本间的距离：$d_{min}(C_i,C_j) = min_{x_i \\in C_i,x_j \\in C_j} dist(x_i,x_j)$  —— 式(10)\n",
    "\n",
    "> 簇$C_i$与簇$C_j$中心点间的距离：$d_{cen}(C_i,C_j) = dist(\\mu_i ,\\mu_j)$   —— 式(11)\n",
    "\n",
    "其中：\n",
    "- dist(.,.)用于计算两个样本之间的距离(具体计算方法见后文)；\n",
    "- $\\mu$ 代表簇C的中心点$\\mu = \\frac{1}{|C|}\\sum_{1 \\leq i \\leq |C|}x_i$ 。\n",
    "\n",
    "\n",
    "基于式（8）~（11)可导出下面这些常用的聚类性能度量内部指标：\n",
    "\n",
    "- DB指数（Davies-Bouldin Index，简称DBI)\n",
    "\n",
    "> $ DBI = \\frac{1}{k} \\sum_{i=1}^{k}max_{j \\neq i}(\\frac{avg(C_i)+avg(C_j)}{d_{cen}(\\mu_i,\\mu_j)})$  —— 式(12)\n",
    "\n",
    "- Dunn指数（Dunn Index，简称DI)\n",
    "\n",
    "> $DI = min_{1 \\leq i \\leq k}{min_{j \\neq i} (\\frac{d_{min}(C_i,C_j)}{max_{1 \\leq l \\leq k}diam(C_l)})}$   —— 式(13)\n",
    "\n",
    "显然，DBI的值越小越好，而DI则相反，越大越好。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 距离计算\n",
    "\n",
    "对函数dist(.,.),若它是一个“距离向量”（distance measure），则需要满足一些基本性质：\n",
    "\n",
    "- 非负性：$ dist(x_i,x_j) \\geq 0$ —— 式(14)\n",
    "- 同一性：$ dist(x_i,x_j) = 0 $当前仅当$x_i= x_j$ ——式(15)\n",
    "- 对称性：$ dist(x_i,x_j) = dist(x_j,x_i) $ —— 式(16)\n",
    "- 直递性：$ dist(x_i,x_j) \\leq dist(x_i,x_k) + dist(x_k,x_j)$ —— 式(17)\n",
    "\n",
    "### 闵可夫斯基距离\n",
    "\n",
    "给定样本$x_i = (x_{i1};x_{i2};...;x_{in})$ 与$x_j = (x_{j1};x_{j2};...;x_{jn})$，最常用的式“闵可夫斯基距离”（Minkowski distance）：\n",
    "\n",
    "> $dist_{mk}(x_i,x_j) = (\\sum_{u=1}^n|x_{iu} - x_{ju}|^p)^\\frac{1}{p}$  —— 式(18)\n",
    "\n",
    "对$p \\geq 1$，式（18）显然满足式（14）~式（18）的距离度量基本性质。其实，式（18）即为$x_i-x_j$的$L_p$范数$||x_i-x_j||_p$\n",
    "\n",
    "> L-P范数是一组范数，$L_p = ||X||_p = \\sqrt[p]{\\sum_{i=1}^{n} |x_i|^p}, X = (x_1,x_2,...,x_n)$ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "根据$dist_{mk}(x_i,x_j) = (\\sum_{u=1}^n|x_{iu} - x_{ju}|^p)^\\frac{1}{p}$ \n",
    "\n",
    "- p=2时，即为欧式距离（Euclidean distance）\n",
    "- p=1时，即为曼哈顿距离（Manhattan distance)，也称为“街区距离”（city block distance）\n",
    "\n",
    "我们常将属性划分为：\n",
    "- “连续属性”（continuous attribute）或“数值属性”（numerical attribute）\n",
    "- “离散数学”（categorical attribute）或“列命属性”（nominal attribute）\n",
    "\n",
    "连续属性在定义域上有无穷多个可能的取值，而离散属性在定义域上是有限个取值。\n",
    "\n",
    "然而在讨论距离计算时，属性上是否定义了“序”关系更为重要。\n",
    "\n",
    "例如定义域为{1，2，3}的离散属性与连续属性的性质更接近一些，能直接在属性值上计算距离：“1”与“2”比较接近、与“3”比较远，这样的属性称为“有序”属性（ordinal attribute）；而定义域为{飞机，火车，轮船}这样的离散属性则不能直接在属性值上计算距离，称为“无序属性”（non-ordinal attribute）。\n",
    "\n",
    "显然，**闵可夫斯基距离可用于有序属性。**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### VDM距离\n",
    "\n",
    "对于无序属性，可采用VDM（Value Difference Metric）。\n",
    "\n",
    "令$m_{u,a}$表示在属性u上取值为a的样本数，$m_{u,a,i}$表示在第i个样本属性u上取值为a的样本数，k为样本簇数，则属性u上两个离散值a与b之间的VDM距离为：\n",
    "\n",
    "> $VDM_p(a,b) = \\sum_{i=1}^k|\\frac{m_{u,a,i}}{m_{u,a}}-\\frac{m_{u,b,i}}{m_{u,b}}|^p$ —— 式（21）\n",
    "\n",
    "于是，**将闵可夫斯基距离和VDM结合即可处理混合属性。**\n",
    "\n",
    "假定有$n_c$个有序属性、$n-n_c$个无序属性，不失一般性，令有序属性排列在无序属性之前，则有：\n",
    "\n",
    "> $MinkovDM_p(x_i,x_j) = (\\sum_{u=1}^{n_c}|x_{iu}-x_{ju}|^p + \\sum_{u=n_c+1}^n VDM_p(x_{iu},x_{ju}))^\\frac{1}{p}$  ——式（22）\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 加权距离\n",
    "\n",
    "当样本空间中不同属性的重要性不同时，可使用“加权距离”（weighted distance）。以加权闵可夫斯基距离为例：\n",
    "\n",
    "$dist_{wmk}(x_i,x_j) = (\\sum_{u=1}^n \\omega_u|x_{iu} - x_{ju}|^p)^\\frac{1}{p}$  —— 式(23)\n",
    "\n",
    "其中，权重$\\omega_u \\geq 0 (i = 1,2,...n)$表征不同属性的重要性，通常$\\sum_{u=1}^n \\omega_u = 1$。\n",
    "\n",
    "需要注意的是，通常我们是基于某种形式的距离来定义“相似度度量”（similarity measure），距离越大，相似度越小。然而，用于相似度度量的距离未必一定要满足距离度量的所有基本性质，尤其是直递性（式17）。\n",
    "\n",
    "例如：可能要“人”“马”分别与“人马”相似，但“人”与“马”很不相似。要达到这个目的可令“人”、“马”与“人马”之间的距离都比较小，但“人”与“马”之间的距离很大。**此时该距离不再满足直递性，这样的距离称为“非度量距离”（non-metric distance）**。\n",
    "\n",
    "此外，本节介绍的距离计算式都是事先定义好的，但有些任务中，有必要基于数据样本来确定合适的距离计算式，或者可通过“距离度量学习”（distance metric learning）来实现。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### “非度量距离”（non-metric distance）举例\n",
    "![ “非度量距离”（non-metric distance）举例](images\\clustering\\非度量距离例子.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 原型聚类\n",
    "\n",
    "原型聚类亦称为“基于原型的聚类”（prototype-based clustering），此类算法假设聚类结构能通过一组原型刻画，在现实聚类任务中极为常用。\n",
    "\n",
    "通常情形下，算法先对原型进行初始化，然后对原型进行迭代更新求解。\n",
    "\n",
    "采用不同的原型表示、不同的求解方式，将产生不同的算法。下面是一些著名的原型聚类算法：\n",
    "\n",
    "- k均值算法\n",
    "- 学习向量量化\n",
    "- 高斯混合聚类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### K-MEANS算法\n",
    "\n",
    "K-Means算法是一种典型的聚类算法。\n",
    "\n",
    "#### 一般形式：\n",
    "\n",
    "给定样本集 $ D = \\{x_1,x_2,...，x_m\\}$，“k均值”（k-means）算法针对聚类所得簇划分 $ C = \\{C_1,C_2,...,C_k\\}$ 最小化平方误差：\n",
    "\n",
    "$ E = \\sum_{i=1}^k \\sum_{x \\in C_i}||x- \\mu_i||_2^2$ ——式（24）\n",
    "\n",
    "其中，$\\mu_i = \\frac{1}{|C_i|}\\sum_{x \\in C_i}x$ 是簇$C_i$的均值向量。\n",
    "\n",
    "直观来看，式（24）在一定程度上刻画了簇内样本围绕簇均值向量的紧密程度，E值越小则簇内样本相似度越高。\n",
    "\n",
    "#### 最小化\n",
    "\n",
    "求式（24）的最小化并不容易，找到它的最优解需要考查样本集D所有可能的簇划分，这是一个NP难题（Aloise et al. 2009)。\n",
    "\n",
    "因此，k均值算法采用了贪心策略，通过迭代优化来近似求解式（24）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### k均值算法流程（贪心策略）\n",
    "\n",
    "K-means聚类算法以k为参数，把n各对象分成k个簇，使簇内具有较高的相似度，而簇间的相似度较低。它的基本思想有以下几点：\n",
    "\n",
    "  - 随机选择k个点，作为初始的聚类中心；\n",
    "  - 对于剩下的点，根据其与聚类中心的距离，将其归入最近的簇；\n",
    "  - 对每个簇,计算所有点的均值作为新的聚类中心；\n",
    "  - 重复上述两步直到聚类中心不再发生改变。\n",
    "\n",
    "请看下面图示：\n",
    "图1：给定一个数据集；\n",
    "![图1](images\\clustering\\example1.jpg)\n",
    "图2：根据K = 5初始化聚类中心，保证　聚类中心处于数据空间内；\n",
    "![图2](images\\clustering\\example2.jpg)\n",
    "图3：根据计算类内对象和聚类中心之间的相似度指标，将数据进行划分；\n",
    "![图3](images\\clustering\\example3.jpg)\n",
    "图4：将类内之间数据的均值作为聚类中心，更新聚类中心。\n",
    "![图4](images\\clustering\\example4.jpg)\n",
    "最后判断算法结束与否即可，目的是为了保证算法的收敛。\n",
    "\n",
    "![k均值算法流程](images\\clustering\\k均值算法流程.png)\n",
    "\n",
    "下面以下表所示数据为例，进行演示k-mean算法的学习过程。\n",
    "\n",
    "![西瓜数据集4](images\\clustering\\西瓜数据集4.png)\n",
    "\n",
    "假定聚类簇数 k=3，算法开始时随机选取三个样本$x_6,x_{12},x_{27}$作为起始均值向量，即：\n",
    "\n",
    "$\\mu_1 = (0.403;0.237), \\mu_2 = (0.343;0.099), \\mu_3 = (0.532;0.472)$\n",
    "\n",
    "考察样本$x_1 = (0.697;0.460)$,它与当前均值向量 $\\mu_1,\\mu_2,\\mu_3$ 的距离分别为0.369，0.506，0.166.因此$x_1$被划入簇$C_3$中。类似的，对数据集中的所有样本考察一遍后，可得当前簇划分为：\n",
    "\n",
    "$C_1 = \\{x_5,x_6,x_7,x_8,x_9,x_10,x_13,x_14,x_17,x_18,x_19,x_20,x_23\\}$\n",
    "\n",
    "$C_2 = \\{x_11,x_12,x_16\\}$\n",
    "\n",
    "$C_3 = \\{x_1,x_2,x_3,x_4,x_21,x_22,x_24,x_25,x_26,x_27,x_28,x_29,x_30\\}$\n",
    "\n",
    "于是，可从$C_1,C_2,C_3 $分别求出新的均值向量：\n",
    "\n",
    "$\\mu_1^{'} = (0.473;0.214), \\mu_2^{'} = (0.394;0.066), \\mu_3^{'} = (0.623;0.388)$\n",
    "\n",
    "更新当前均值向量后，不断重复上述过程，如下图所示，第五轮迭代产生的结果与第四轮迭代相同，于是算法停止，得到最终的簇划分。\n",
    "\n",
    "![kmean聚类西瓜集4](images\\clustering\\kmean聚类西瓜集4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 贪心算法\n",
    "\n",
    "在每一步求解的步骤中，它要求“贪婪”的选择最佳操作，并希望通过一系列的最优选择，能够产生一个问题的（全局的）最优解。\n",
    "\n",
    "贪心算法每一步必须满足一下条件：\n",
    "\n",
    "- 可行的：即它必须满足问题的约束。\n",
    "\n",
    "- 局部最优：他是当前步骤中所有可行选择中最佳的局部选择。\n",
    "\n",
    "- 不可取消：即选择一旦做出，在算法的后面步骤就不可改变了。\n",
    "\n",
    "例如：\n",
    "\n",
    "【活动选择问题】这是《算法导论》上的例子，也是一个非常经典的问题。有n个需要在同一天使用同一个教室的活动a1,a2,…,an，教室同一时刻只能由一个活动使用。每个活动ai都有一个开始时间si和结束时间fi 。一旦被选择后，活动ai就占据半开时间区间[si,fi)。如果[si,fi]和[sj,fj]互不重叠，ai和aj两个活动就可以被安排在这一天。该问题就是要安排这些活动使得尽量多的活动能不冲突的举行。例如下图所示的活动集合S，其中各项活动按照结束时间单调递增排序。\n",
    "\n",
    "用贪心法的话思想很简单：活动越早结束，剩余的时间是不是越多？那我就早最早结束的那个活动，找到后在剩下的活动中再找最早结束的不就得了？\n",
    "\n",
    "虽然贪心算法的思想简单，但是贪心法不保证能得到问题的最优解，如果得不到最优解，那就不是我们想要的东西了，所以我们现在要证明的是在这个问题中，用贪心法能得到最优解。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### k-means的应用案例\n",
    "\n",
    "- 数据介绍\n",
    "\n",
    "现有1999年全国31个省份城镇居民家庭平均每人全年消费性支出的八个主要变量数据，这8个变量分别是：**食品、衣着、家庭设备用品及服务、医疗保健、交通和通信、娱乐教育文化服务、居住、杂项商品和服务**。\n",
    "\n",
    "\n",
    "- 实验目的\n",
    "\n",
    "通过聚类，将1999年各个省份的消费水平划分为4个等级。\n",
    "\n",
    "\n",
    "- 技术路线\n",
    "\n",
    "使用 sklearn.cluster.Kmeans算法，进行聚类学习。\n",
    "\n",
    "\n",
    "- 实验过程\n",
    "\n",
    "  + step 1 读取数据\n",
    "  + step 2 数据预处理\n",
    "  + step 3 训练模型，确定k的数目\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>地区</th>\n",
       "      <th>食品</th>\n",
       "      <th>衣着</th>\n",
       "      <th>家庭设备用品及服务</th>\n",
       "      <th>医疗保健</th>\n",
       "      <th>交通和通信</th>\n",
       "      <th>娱乐教育文化服务</th>\n",
       "      <th>居住</th>\n",
       "      <th>杂项商品和服务</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>北京</td>\n",
       "      <td>2959.19</td>\n",
       "      <td>730.79</td>\n",
       "      <td>749.41</td>\n",
       "      <td>513.34</td>\n",
       "      <td>467.87</td>\n",
       "      <td>1141.82</td>\n",
       "      <td>478.42</td>\n",
       "      <td>457.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>天津</td>\n",
       "      <td>2459.77</td>\n",
       "      <td>495.47</td>\n",
       "      <td>697.33</td>\n",
       "      <td>302.87</td>\n",
       "      <td>284.19</td>\n",
       "      <td>735.97</td>\n",
       "      <td>570.84</td>\n",
       "      <td>305.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>河北</td>\n",
       "      <td>1495.63</td>\n",
       "      <td>515.90</td>\n",
       "      <td>362.37</td>\n",
       "      <td>285.32</td>\n",
       "      <td>272.95</td>\n",
       "      <td>540.58</td>\n",
       "      <td>364.91</td>\n",
       "      <td>188.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>山西</td>\n",
       "      <td>1406.33</td>\n",
       "      <td>477.77</td>\n",
       "      <td>290.15</td>\n",
       "      <td>208.57</td>\n",
       "      <td>201.50</td>\n",
       "      <td>414.72</td>\n",
       "      <td>281.84</td>\n",
       "      <td>212.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>内蒙古</td>\n",
       "      <td>1303.97</td>\n",
       "      <td>524.29</td>\n",
       "      <td>254.83</td>\n",
       "      <td>192.17</td>\n",
       "      <td>249.81</td>\n",
       "      <td>463.09</td>\n",
       "      <td>287.87</td>\n",
       "      <td>192.96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    地区       食品      衣着  家庭设备用品及服务    医疗保健   交通和通信  娱乐教育文化服务      居住  杂项商品和服务\n",
       "0   北京  2959.19  730.79     749.41  513.34  467.87   1141.82  478.42   457.64\n",
       "1   天津  2459.77  495.47     697.33  302.87  284.19    735.97  570.84   305.08\n",
       "2   河北  1495.63  515.90     362.37  285.32  272.95    540.58  364.91   188.63\n",
       "3   山西  1406.33  477.77     290.15  208.57  201.50    414.72  281.84   212.10\n",
       "4  内蒙古  1303.97  524.29     254.83  192.17  249.81    463.09  287.87   192.96"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"数据概览\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "\n",
    "df  = pd.read_csv('data/clustering/31city.txt',names=['地区','食品','衣着','家庭设备用品及服务','医疗保健','交通和通信','娱乐教育文化服务','居住','杂项商品和服务'],encoding='gb2312')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**sklearn中使用K-Means方法所需的参数有：**\n",
    "\n",
    "- n_clusters: 用于指定聚类中心的个数；\n",
    "- init：初始聚类中心的初始化方法；\n",
    "- max_iter：最大的迭代次数；\n",
    "\n",
    "一般调用时只能给出n_clusters即可，init默认是k-means++ ,max_iter默认为300."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 1 0 0 0 0 0 0 3 2 1 2 1 0 0 0 2 2 3 2 2 1 2 0 2 1 0 0 0 0 0]\n",
      "消费指数:3788.76\n",
      "['河北', '山西', '内蒙古', '辽宁', '吉林', '黑龙江', '江西', '山东', '河南', '贵州', '陕西', '甘肃', '青海', '宁夏', '新疆']\n",
      "消费指数:5678.62\n",
      "['天津', '浙江', '福建', '重庆', '西藏']\n",
      "消费指数:4512.27\n",
      "['江苏', '安徽', '湖南', '湖北', '广西', '海南', '四川', '云南']\n",
      "消费指数:7754.66\n",
      "['北京', '上海', '广东']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import KMeans \n",
    "from sklearn.model_selection import train_test_split,cross_val_score\n",
    "from sklearn import preprocessing\n",
    "\n",
    "df_scaled = preprocessing.scale(df.iloc[:,1:])\n",
    "\n",
    "cluster = KMeans(n_clusters=4)#将各省消费水平分为4个等次\n",
    "\n",
    "label = cluster.fit_predict(df.iloc[:,1:])\n",
    "print(label)\n",
    "expenses = np.sum(cluster.cluster_centers_ ,axis = 1)\n",
    "CityCluster = [[],[],[],[]]\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "    CityCluster[label[i]].append(df.iloc[i,0])\n",
    "\n",
    "for i in range(len(CityCluster)):\n",
    "    print(\"消费指数:%.2f\" % expenses[i])\n",
    "    print(CityCluster[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 密度聚类\n",
    "\n",
    "密度聚类也称为“基于密度的聚类”（density-based clustering）。\n",
    "\n",
    "此类算法假设聚类结构能够通过样本分布的紧密程度确定。通常情况下，密度聚类算法从样本密度的角度来考察样本之间的可连接性，并基于可连接样本不断扩展聚类簇，以获得最终的聚类结果。\n",
    "\n",
    "### DBSCAN 方法\n",
    "\n",
    "DBSCAN是一种著名的密度聚类算法，它不需要预先指定簇的个数，但最终的簇个数不确定。\n",
    "\n",
    "DBSCAN基于一组“邻域”（neighborhood)参数$(\\epsilon, MinPts)$来刻画样本分布的紧密程度。\n",
    "\n",
    "给定数据集$D = \\{x_1,x_2,..,x_m\\}$，定义下面这几个概念：\n",
    "\n",
    "- $\\epsilon $ -邻域：对 $x_j \\in D$，其 $\\epsilon $ -邻域 包含样本集D中与$x_j$的距离不大于$\\epsilon$的样本，即$N_{\\epsilon}(x_j) = \\{x_i \\in D |dist(x_i,x_j) \\leq \\epsilon \\}$\n",
    "\n",
    "- 核心对象（core object）：若$x_j$的 $\\epsilon $ -邻域至少包含MinPts个样本，即$|N_{\\epsilon}(x_j)| \\geq MinPts$，则$x_j$是一个核心对象；\n",
    "\n",
    "- 密度直达（directly density-reachable）：若$x_j$位于$x_i$的$\\epsilon $ -邻域中，且$x_i$是核心对象，则称$x_j$由 $x_i$密度直达；密度直达关系通常不满足对称性。\n",
    "\n",
    "- 密度可达（density-reachale）：对$x_i$与$x_j$，若存在样本序列$p_1,p_2,...,p_n$，其中$p_1 = x_i,p_n = x_j$ 且$p_{i+1}$由$p_i$密度直达，则称$x_j$由$x_i$密度可达；密度可达关系满足直递性，不满足对称性。\n",
    "\n",
    "- 密度相连（density-connected）：对$x_i$与$x_j$，若存在$x_k$使得$x_i$与$x_j$均由$x_k$密度可达，则称$x_i$与$x_j$密度相连。密度相连关系满足对称性。\n",
    "\n",
    "![dbscan基本概念的示意图](images/clustering/dbscan基本概念的示意图.png)\n",
    "\n",
    "基于这些概念，**DBSCAN将“簇”定义为：由密度可达关系导出的最大的密度相连样本集合**。形式化地说，给定邻域参数$(\\epsilon , MinPts)$，簇$ C \\subseteq D$是满足以下性质的非空样本子集：\n",
    "\n",
    "> 连结性（connectivity）：$x_i \\in C ,x_j \\in C \\rightarrow x_i 与 x_j密度相连$  ——式（39）\n",
    "\n",
    "> 最大性（maximality）：$x_i \\in C x_j 由 x_i 密度可达 \\rightarrow x_j \\in C$  ——式（40）\n",
    "\n",
    "那么？如何从数据集D中找出满足以上性质的聚类簇呢？\n",
    "\n",
    "实际上，若x为核心对象，由x的密度可达的所有样本组成的集合记为$X = \\{ x' \\in D |x' 由x密度可达\\}$，则不难证明X即为满足连结性和最大性的簇。\n",
    "\n",
    "于是，DBSCAN算法先任选数据集中的一个核心对象为“种子”（seed），再由此出发确定相应的聚类簇，算法描述如下：\n",
    "\n",
    "![DBSCAN算法](images/clustering/DBSCAN算法.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 实例\n",
    "\n",
    "- 数据介绍\n",
    "\n",
    "现有大学校园网的日志数据，290条大学生的校园网使用情况数据，数据包括：（ 记录编号,学生ID,MAC地址,IP地址,开始上网时间,停止上网时间,上网时长,子网号,学生网络模板,套餐类型,联网类型）。\n",
    "\n",
    "![学生上网记录数据样本示例](images/clustering/学生上网记录数据样本示例.png)\n",
    "\n",
    "\n",
    "- 实验目的\n",
    "\n",
    "通过聚类，利用已有数据，分析学生上网的分簇模式。\n",
    "\n",
    "- 技术路线\n",
    "\n",
    "使用 sklearn.cluster.DBSCAN算法，进行聚类学习。\n",
    "\n",
    "\n",
    "- 实验过程\n",
    "\n",
    "  + step 1 读取数据\n",
    "  + step 2 数据预处理\n",
    "  + step 3 训练模型\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>记录编号</th>\n",
       "      <th>学生ID</th>\n",
       "      <th>MAC地址</th>\n",
       "      <th>IP地址</th>\n",
       "      <th>开始上网时间</th>\n",
       "      <th>停止上网时间</th>\n",
       "      <th>上网时长</th>\n",
       "      <th>子网号</th>\n",
       "      <th>学生网络模板</th>\n",
       "      <th>套餐类型</th>\n",
       "      <th>联网类型</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2c929293466b97a6014754607e457d68</td>\n",
       "      <td>U201215025</td>\n",
       "      <td>A417314EEA7B</td>\n",
       "      <td>10.12.49.26</td>\n",
       "      <td>2014-07-20 22:44:18.540000000</td>\n",
       "      <td>2014-07-20 23:10:16.540000000</td>\n",
       "      <td>1558</td>\n",
       "      <td>15</td>\n",
       "      <td>本科生动态IP模版</td>\n",
       "      <td>100元每半年</td>\n",
       "      <td>internet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2c929293466b97a60147546099a57d81</td>\n",
       "      <td>U201116197</td>\n",
       "      <td>F0DEF1C78366</td>\n",
       "      <td>222.20.71.38</td>\n",
       "      <td>2014-07-20 12:14:21.380000000</td>\n",
       "      <td>2014-07-20 23:25:22.380000000</td>\n",
       "      <td>40261</td>\n",
       "      <td>1</td>\n",
       "      <td>本科生动态IP模版</td>\n",
       "      <td>20元每月</td>\n",
       "      <td>internet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2c929293466b97a60147546099fa7d86</td>\n",
       "      <td>M201373803</td>\n",
       "      <td>88539523E88D</td>\n",
       "      <td>10.12.59.230</td>\n",
       "      <td>2014-07-20 22:56:41.593000000</td>\n",
       "      <td>2014-07-20 23:25:22.593000000</td>\n",
       "      <td>1721</td>\n",
       "      <td>15</td>\n",
       "      <td>研究生动态IP模版</td>\n",
       "      <td>计天</td>\n",
       "      <td>internet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2c929293466b97a6014754609a137d88</td>\n",
       "      <td>M201370611</td>\n",
       "      <td>F0DEF167324F</td>\n",
       "      <td>218.197.241.94</td>\n",
       "      <td>2014-07-20 23:19:30.930000000</td>\n",
       "      <td>2014-07-20 23:25:21.930000000</td>\n",
       "      <td>351</td>\n",
       "      <td>1</td>\n",
       "      <td>研究生动态IP模版</td>\n",
       "      <td>20元包月</td>\n",
       "      <td>internet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2c929293466b97a601475460ab577d99</td>\n",
       "      <td>U201112081</td>\n",
       "      <td>B888E3813D3C</td>\n",
       "      <td>218.197.229.5</td>\n",
       "      <td>2014-07-20 16:51:56.657000000</td>\n",
       "      <td>2014-07-20 23:24:40.657000000</td>\n",
       "      <td>23564</td>\n",
       "      <td>1</td>\n",
       "      <td>本科生动态IP模版</td>\n",
       "      <td>1元每天</td>\n",
       "      <td>internet</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               记录编号        学生ID         MAC地址            IP地址  \\\n",
       "0  2c929293466b97a6014754607e457d68  U201215025  A417314EEA7B     10.12.49.26   \n",
       "1  2c929293466b97a60147546099a57d81  U201116197  F0DEF1C78366    222.20.71.38   \n",
       "2  2c929293466b97a60147546099fa7d86  M201373803  88539523E88D    10.12.59.230   \n",
       "3  2c929293466b97a6014754609a137d88  M201370611  F0DEF167324F  218.197.241.94   \n",
       "4  2c929293466b97a601475460ab577d99  U201112081  B888E3813D3C   218.197.229.5   \n",
       "\n",
       "                          开始上网时间                         停止上网时间   上网时长  子网号  \\\n",
       "0  2014-07-20 22:44:18.540000000  2014-07-20 23:10:16.540000000   1558   15   \n",
       "1  2014-07-20 12:14:21.380000000  2014-07-20 23:25:22.380000000  40261    1   \n",
       "2  2014-07-20 22:56:41.593000000  2014-07-20 23:25:22.593000000   1721   15   \n",
       "3  2014-07-20 23:19:30.930000000  2014-07-20 23:25:21.930000000    351    1   \n",
       "4  2014-07-20 16:51:56.657000000  2014-07-20 23:24:40.657000000  23564    1   \n",
       "\n",
       "      学生网络模板     套餐类型      联网类型  \n",
       "0  本科生动态IP模版  100元每半年  internet  \n",
       "1  本科生动态IP模版    20元每月  internet  \n",
       "2  研究生动态IP模版       计天  internet  \n",
       "3  研究生动态IP模版    20元包月  internet  \n",
       "4  本科生动态IP模版     1元每天  internet  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load data\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data/clustering/studentnetuse.txt',names=['记录编号','学生ID','MAC地址','IP地址','开始上网时间','停止上网时间','上网时长','子网号','学生网络模板','套餐类型','联网类型'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n",
      "Estimated number of clusters: 3\n",
      "Estimated number of noise points: 18\n",
      "Homogeneity: 0.953\n",
      "Completeness: 0.883\n",
      "V-measure: 0.917\n",
      "Adjusted Rand Index: 0.952\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "adjusted_mutual_info_score() got an unexpected keyword argument 'average_method'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-95251211d89b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"V-measure: %0.3f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv_measure_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Adjusted Rand Index: %0.3f\"\u001b[0m  \u001b[0;34m%\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madjusted_rand_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Adjusted Mutual Information: %0.3f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madjusted_mutual_info_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maverage_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'arithmetic'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Silhouette Coefficient: %0.3f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msilhouette_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: adjusted_mutual_info_score() got an unexpected keyword argument 'average_method'"
     ]
    }
   ],
   "source": [
    "print(__doc__)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn import metrics\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# #############################################################################\n",
    "# Generate sample data\n",
    "centers = [[1, 1], [-1, -1], [1, -1]]\n",
    "X, labels_true = make_blobs(n_samples=750, centers=centers, cluster_std=0.4,random_state=0)\n",
    "\n",
    "X = StandardScaler().fit_transform(X)\n",
    "\n",
    "# #############################################################################\n",
    "# Compute DBSCAN\n",
    "db = DBSCAN(eps=0.3, min_samples=10).fit(X)\n",
    "core_samples_mask = np.zeros_like(db.labels_, dtype=bool)\n",
    "core_samples_mask[db.core_sample_indices_] = True\n",
    "labels = db.labels_\n",
    "\n",
    "# Number of clusters in labels, ignoring noise if present.\n",
    "n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "n_noise_ = list(labels).count(-1)\n",
    "\n",
    "print('Estimated number of clusters: %d' % n_clusters_)\n",
    "print('Estimated number of noise points: %d' % n_noise_)\n",
    "print(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(labels_true, labels))\n",
    "print(\"Completeness: %0.3f\" % metrics.completeness_score(labels_true, labels))\n",
    "print(\"V-measure: %0.3f\" % metrics.v_measure_score(labels_true, labels))\n",
    "print(\"Adjusted Rand Index: %0.3f\"  % metrics.adjusted_rand_score(labels_true, labels))\n",
    "print(\"Adjusted Mutual Information: %0.3f\" % metrics.adjusted_mutual_info_score(labels_true, labels,average_method='arithmetic'))\n",
    "print(\"Silhouette Coefficient: %0.3f\" % metrics.silhouette_score(X, labels))\n",
    "\n",
    "# #############################################################################\n",
    "# Plot result\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Black removed and is used for noise instead.\n",
    "unique_labels = set(labels)\n",
    "colors = [plt.cm.Spectral(each)\n",
    "          for each in np.linspace(0, 1, len(unique_labels))]\n",
    "for k, col in zip(unique_labels, colors):\n",
    "    if k == -1:\n",
    "        # Black used for noise.\n",
    "        col = [0, 0, 0, 1]\n",
    "\n",
    "    class_member_mask = (labels == k)\n",
    "\n",
    "    xy = X[class_member_mask & core_samples_mask]\n",
    "    plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=tuple(col),\n",
    "             markeredgecolor='k', markersize=14)\n",
    "\n",
    "    xy = X[class_member_mask & ~core_samples_mask]\n",
    "    plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=tuple(col),\n",
    "             markeredgecolor='k', markersize=6)\n",
    "\n",
    "plt.title('Estimated number of clusters: %d' % n_clusters_)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
