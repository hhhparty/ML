{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 神经网络与tensorflow\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tensorflow介绍\n",
    "\n",
    "TensorFlow 是一个用于人工智能的开源神器。\n",
    "\n",
    "TensorFlow是一个采用数据流图（data flow graphs），用于数值计算的开源软件库。\n",
    "\n",
    "它灵活的架构让你可以在多种平台上展开计算，例如台式计算机中的一个或多个CPU（或GPU），服务器，移动设备等等。\n",
    "\n",
    "TensorFlow 最初由Google大脑小组的研究员和工程师们开发出来，用于机器学习和深度神经网络方面的研究，但这个系统的通用性使其也可广泛用于其他计算领域。\n",
    "\n",
    "\n",
    "使用 TensorFlow, 你必须明白 TensorFlow:\n",
    "\n",
    "- 使用图 (graph) 来表示计算任务；\n",
    "- 图中的节点被称为op（operation）；\n",
    "- 在被称之为 会话 (Session) 的上下文 (context) 中执行图；\n",
    "- 使用 tensor (也叫张量、数组)表示数据；\n",
    "- 每个tensor是一个类型化的多维数组；\n",
    "  + 例如, 你可以将一小组图像集表示为一个四维浮点数数组, 这四个维度分别是[batch, height, width, channels].\n",
    "  \n",
    "- 一个节点可以获得0个或多个tensor（数据）进行计算，产生0或多个tensor;\n",
    "- 通过变量 (Variable) 维护状态.\n",
    "- 使用 feed 和 fetch 可以为任意的操作(arbitrary operation) 赋值或者从其中获取数据.\n",
    "\n",
    "\n",
    "\n",
    "一个 TensorFlow 图描述了计算的过程. 为了进行计算, 图必须在会话里被启动。\n",
    "\n",
    "会话将图的 op 分发到诸如 CPU 或 GPU 之类的设备上, 同时提供执行 op 的方法. 这些方法执行后, 将产生的 tensor 返回。\n",
    "\n",
    "在 Python 语言中, 返回的 tensor 是 numpy ndarray 对象。\n",
    "\n",
    "让我们先看一段使用 Python API 撰写的 TensorFlow 示例代码, 对将要学习的内容有初步的印象.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用 tensorflow 实现神经网络学习器的过程\n",
    "\n",
    "1. 准备数据;\n",
    "2. 定义节点准备接收数据;\n",
    "3. 定义隐藏层和输出层；\n",
    "4. 定义损失函数；\n",
    "5. 选定优化器，设定训练方法（使损失最小化）；\n",
    "6. 对所有变量进行初始化，在会话中运行优化器，迭代1000次进行反馈学习。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义神经网络层的构建方法\n",
    "\n",
    "用tf.Variable定义变量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# 先写一个添加层的函数（可以一会儿再理解它）\n",
    "def add_layer(inputs, in_size, out_size, activation_function=None):\n",
    "    # 增加一个以上的层，并返回该层的输出。\n",
    "    # 下面定义了神经元相关的权重、阈值、激活函数 \n",
    "    Weights = tf.Variable(tf.random_normal([in_size, out_size]))# 初始化连接权重\n",
    "    biases = tf.Variable(tf.zeros([1, out_size]) + 0.1)# 初始化阈值\n",
    "    Wx_plus_b = tf.matmul(inputs, Weights) + biases #matmul指矩阵乘法,这里实际上定义了前向传播过程\n",
    "    if activation_function is None:\n",
    "        outputs = Wx_plus_b\n",
    "    else:\n",
    "        outputs = activation_function(Wx_plus_b)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 准备数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.         -0.99331104 -0.98662207 -0.97993311 -0.97324415 -0.96655518\n",
      " -0.95986622 -0.95317726 -0.94648829 -0.93979933 -0.93311037 -0.9264214\n",
      " -0.91973244 -0.91304348 -0.90635452 -0.89966555 -0.89297659 -0.88628763\n",
      " -0.87959866 -0.8729097  -0.86622074 -0.85953177 -0.85284281 -0.84615385\n",
      " -0.83946488 -0.83277592 -0.82608696 -0.81939799 -0.81270903 -0.80602007\n",
      " -0.7993311  -0.79264214 -0.78595318 -0.77926421 -0.77257525 -0.76588629\n",
      " -0.75919732 -0.75250836 -0.7458194  -0.73913043 -0.73244147 -0.72575251\n",
      " -0.71906355 -0.71237458 -0.70568562 -0.69899666 -0.69230769 -0.68561873\n",
      " -0.67892977 -0.6722408  -0.66555184 -0.65886288 -0.65217391 -0.64548495\n",
      " -0.63879599 -0.63210702 -0.62541806 -0.6187291  -0.61204013 -0.60535117\n",
      " -0.59866221 -0.59197324 -0.58528428 -0.57859532 -0.57190635 -0.56521739\n",
      " -0.55852843 -0.55183946 -0.5451505  -0.53846154 -0.53177258 -0.52508361\n",
      " -0.51839465 -0.51170569 -0.50501672 -0.49832776 -0.4916388  -0.48494983\n",
      " -0.47826087 -0.47157191 -0.46488294 -0.45819398 -0.45150502 -0.44481605\n",
      " -0.43812709 -0.43143813 -0.42474916 -0.4180602  -0.41137124 -0.40468227\n",
      " -0.39799331 -0.39130435 -0.38461538 -0.37792642 -0.37123746 -0.36454849\n",
      " -0.35785953 -0.35117057 -0.34448161 -0.33779264 -0.33110368 -0.32441472\n",
      " -0.31772575 -0.31103679 -0.30434783 -0.29765886 -0.2909699  -0.28428094\n",
      " -0.27759197 -0.27090301 -0.26421405 -0.25752508 -0.25083612 -0.24414716\n",
      " -0.23745819 -0.23076923 -0.22408027 -0.2173913  -0.21070234 -0.20401338\n",
      " -0.19732441 -0.19063545 -0.18394649 -0.17725753 -0.17056856 -0.1638796\n",
      " -0.15719064 -0.15050167 -0.14381271 -0.13712375 -0.13043478 -0.12374582\n",
      " -0.11705686 -0.11036789 -0.10367893 -0.09698997 -0.090301   -0.08361204\n",
      " -0.07692308 -0.07023411 -0.06354515 -0.05685619 -0.05016722 -0.04347826\n",
      " -0.0367893  -0.03010033 -0.02341137 -0.01672241 -0.01003344 -0.00334448\n",
      "  0.00334448  0.01003344  0.01672241  0.02341137  0.03010033  0.0367893\n",
      "  0.04347826  0.05016722  0.05685619  0.06354515  0.07023411  0.07692308\n",
      "  0.08361204  0.090301    0.09698997  0.10367893  0.11036789  0.11705686\n",
      "  0.12374582  0.13043478  0.13712375  0.14381271  0.15050167  0.15719064\n",
      "  0.1638796   0.17056856  0.17725753  0.18394649  0.19063545  0.19732441\n",
      "  0.20401338  0.21070234  0.2173913   0.22408027  0.23076923  0.23745819\n",
      "  0.24414716  0.25083612  0.25752508  0.26421405  0.27090301  0.27759197\n",
      "  0.28428094  0.2909699   0.29765886  0.30434783  0.31103679  0.31772575\n",
      "  0.32441472  0.33110368  0.33779264  0.34448161  0.35117057  0.35785953\n",
      "  0.36454849  0.37123746  0.37792642  0.38461538  0.39130435  0.39799331\n",
      "  0.40468227  0.41137124  0.4180602   0.42474916  0.43143813  0.43812709\n",
      "  0.44481605  0.45150502  0.45819398  0.46488294  0.47157191  0.47826087\n",
      "  0.48494983  0.4916388   0.49832776  0.50501672  0.51170569  0.51839465\n",
      "  0.52508361  0.53177258  0.53846154  0.5451505   0.55183946  0.55852843\n",
      "  0.56521739  0.57190635  0.57859532  0.58528428  0.59197324  0.59866221\n",
      "  0.60535117  0.61204013  0.6187291   0.62541806  0.63210702  0.63879599\n",
      "  0.64548495  0.65217391  0.65886288  0.66555184  0.6722408   0.67892977\n",
      "  0.68561873  0.69230769  0.69899666  0.70568562  0.71237458  0.71906355\n",
      "  0.72575251  0.73244147  0.73913043  0.7458194   0.75250836  0.75919732\n",
      "  0.76588629  0.77257525  0.77926421  0.78595318  0.79264214  0.7993311\n",
      "  0.80602007  0.81270903  0.81939799  0.82608696  0.83277592  0.83946488\n",
      "  0.84615385  0.85284281  0.85953177  0.86622074  0.8729097   0.87959866\n",
      "  0.88628763  0.89297659  0.89966555  0.90635452  0.91304348  0.91973244\n",
      "  0.9264214   0.93311037  0.93979933  0.94648829  0.95317726  0.95986622\n",
      "  0.96655518  0.97324415  0.97993311  0.98662207  0.99331104  1.        ]\n",
      "[[-1.        ]\n",
      " [-0.99331104]\n",
      " [-0.98662207]\n",
      " [-0.97993311]\n",
      " [-0.97324415]\n",
      " [-0.96655518]\n",
      " [-0.95986622]\n",
      " [-0.95317726]\n",
      " [-0.94648829]\n",
      " [-0.93979933]\n",
      " [-0.93311037]\n",
      " [-0.9264214 ]\n",
      " [-0.91973244]\n",
      " [-0.91304348]\n",
      " [-0.90635452]\n",
      " [-0.89966555]\n",
      " [-0.89297659]\n",
      " [-0.88628763]\n",
      " [-0.87959866]\n",
      " [-0.8729097 ]\n",
      " [-0.86622074]\n",
      " [-0.85953177]\n",
      " [-0.85284281]\n",
      " [-0.84615385]\n",
      " [-0.83946488]\n",
      " [-0.83277592]\n",
      " [-0.82608696]\n",
      " [-0.81939799]\n",
      " [-0.81270903]\n",
      " [-0.80602007]\n",
      " [-0.7993311 ]\n",
      " [-0.79264214]\n",
      " [-0.78595318]\n",
      " [-0.77926421]\n",
      " [-0.77257525]\n",
      " [-0.76588629]\n",
      " [-0.75919732]\n",
      " [-0.75250836]\n",
      " [-0.7458194 ]\n",
      " [-0.73913043]\n",
      " [-0.73244147]\n",
      " [-0.72575251]\n",
      " [-0.71906355]\n",
      " [-0.71237458]\n",
      " [-0.70568562]\n",
      " [-0.69899666]\n",
      " [-0.69230769]\n",
      " [-0.68561873]\n",
      " [-0.67892977]\n",
      " [-0.6722408 ]\n",
      " [-0.66555184]\n",
      " [-0.65886288]\n",
      " [-0.65217391]\n",
      " [-0.64548495]\n",
      " [-0.63879599]\n",
      " [-0.63210702]\n",
      " [-0.62541806]\n",
      " [-0.6187291 ]\n",
      " [-0.61204013]\n",
      " [-0.60535117]\n",
      " [-0.59866221]\n",
      " [-0.59197324]\n",
      " [-0.58528428]\n",
      " [-0.57859532]\n",
      " [-0.57190635]\n",
      " [-0.56521739]\n",
      " [-0.55852843]\n",
      " [-0.55183946]\n",
      " [-0.5451505 ]\n",
      " [-0.53846154]\n",
      " [-0.53177258]\n",
      " [-0.52508361]\n",
      " [-0.51839465]\n",
      " [-0.51170569]\n",
      " [-0.50501672]\n",
      " [-0.49832776]\n",
      " [-0.4916388 ]\n",
      " [-0.48494983]\n",
      " [-0.47826087]\n",
      " [-0.47157191]\n",
      " [-0.46488294]\n",
      " [-0.45819398]\n",
      " [-0.45150502]\n",
      " [-0.44481605]\n",
      " [-0.43812709]\n",
      " [-0.43143813]\n",
      " [-0.42474916]\n",
      " [-0.4180602 ]\n",
      " [-0.41137124]\n",
      " [-0.40468227]\n",
      " [-0.39799331]\n",
      " [-0.39130435]\n",
      " [-0.38461538]\n",
      " [-0.37792642]\n",
      " [-0.37123746]\n",
      " [-0.36454849]\n",
      " [-0.35785953]\n",
      " [-0.35117057]\n",
      " [-0.34448161]\n",
      " [-0.33779264]\n",
      " [-0.33110368]\n",
      " [-0.32441472]\n",
      " [-0.31772575]\n",
      " [-0.31103679]\n",
      " [-0.30434783]\n",
      " [-0.29765886]\n",
      " [-0.2909699 ]\n",
      " [-0.28428094]\n",
      " [-0.27759197]\n",
      " [-0.27090301]\n",
      " [-0.26421405]\n",
      " [-0.25752508]\n",
      " [-0.25083612]\n",
      " [-0.24414716]\n",
      " [-0.23745819]\n",
      " [-0.23076923]\n",
      " [-0.22408027]\n",
      " [-0.2173913 ]\n",
      " [-0.21070234]\n",
      " [-0.20401338]\n",
      " [-0.19732441]\n",
      " [-0.19063545]\n",
      " [-0.18394649]\n",
      " [-0.17725753]\n",
      " [-0.17056856]\n",
      " [-0.1638796 ]\n",
      " [-0.15719064]\n",
      " [-0.15050167]\n",
      " [-0.14381271]\n",
      " [-0.13712375]\n",
      " [-0.13043478]\n",
      " [-0.12374582]\n",
      " [-0.11705686]\n",
      " [-0.11036789]\n",
      " [-0.10367893]\n",
      " [-0.09698997]\n",
      " [-0.090301  ]\n",
      " [-0.08361204]\n",
      " [-0.07692308]\n",
      " [-0.07023411]\n",
      " [-0.06354515]\n",
      " [-0.05685619]\n",
      " [-0.05016722]\n",
      " [-0.04347826]\n",
      " [-0.0367893 ]\n",
      " [-0.03010033]\n",
      " [-0.02341137]\n",
      " [-0.01672241]\n",
      " [-0.01003344]\n",
      " [-0.00334448]\n",
      " [ 0.00334448]\n",
      " [ 0.01003344]\n",
      " [ 0.01672241]\n",
      " [ 0.02341137]\n",
      " [ 0.03010033]\n",
      " [ 0.0367893 ]\n",
      " [ 0.04347826]\n",
      " [ 0.05016722]\n",
      " [ 0.05685619]\n",
      " [ 0.06354515]\n",
      " [ 0.07023411]\n",
      " [ 0.07692308]\n",
      " [ 0.08361204]\n",
      " [ 0.090301  ]\n",
      " [ 0.09698997]\n",
      " [ 0.10367893]\n",
      " [ 0.11036789]\n",
      " [ 0.11705686]\n",
      " [ 0.12374582]\n",
      " [ 0.13043478]\n",
      " [ 0.13712375]\n",
      " [ 0.14381271]\n",
      " [ 0.15050167]\n",
      " [ 0.15719064]\n",
      " [ 0.1638796 ]\n",
      " [ 0.17056856]\n",
      " [ 0.17725753]\n",
      " [ 0.18394649]\n",
      " [ 0.19063545]\n",
      " [ 0.19732441]\n",
      " [ 0.20401338]\n",
      " [ 0.21070234]\n",
      " [ 0.2173913 ]\n",
      " [ 0.22408027]\n",
      " [ 0.23076923]\n",
      " [ 0.23745819]\n",
      " [ 0.24414716]\n",
      " [ 0.25083612]\n",
      " [ 0.25752508]\n",
      " [ 0.26421405]\n",
      " [ 0.27090301]\n",
      " [ 0.27759197]\n",
      " [ 0.28428094]\n",
      " [ 0.2909699 ]\n",
      " [ 0.29765886]\n",
      " [ 0.30434783]\n",
      " [ 0.31103679]\n",
      " [ 0.31772575]\n",
      " [ 0.32441472]\n",
      " [ 0.33110368]\n",
      " [ 0.33779264]\n",
      " [ 0.34448161]\n",
      " [ 0.35117057]\n",
      " [ 0.35785953]\n",
      " [ 0.36454849]\n",
      " [ 0.37123746]\n",
      " [ 0.37792642]\n",
      " [ 0.38461538]\n",
      " [ 0.39130435]\n",
      " [ 0.39799331]\n",
      " [ 0.40468227]\n",
      " [ 0.41137124]\n",
      " [ 0.4180602 ]\n",
      " [ 0.42474916]\n",
      " [ 0.43143813]\n",
      " [ 0.43812709]\n",
      " [ 0.44481605]\n",
      " [ 0.45150502]\n",
      " [ 0.45819398]\n",
      " [ 0.46488294]\n",
      " [ 0.47157191]\n",
      " [ 0.47826087]\n",
      " [ 0.48494983]\n",
      " [ 0.4916388 ]\n",
      " [ 0.49832776]\n",
      " [ 0.50501672]\n",
      " [ 0.51170569]\n",
      " [ 0.51839465]\n",
      " [ 0.52508361]\n",
      " [ 0.53177258]\n",
      " [ 0.53846154]\n",
      " [ 0.5451505 ]\n",
      " [ 0.55183946]\n",
      " [ 0.55852843]\n",
      " [ 0.56521739]\n",
      " [ 0.57190635]\n",
      " [ 0.57859532]\n",
      " [ 0.58528428]\n",
      " [ 0.59197324]\n",
      " [ 0.59866221]\n",
      " [ 0.60535117]\n",
      " [ 0.61204013]\n",
      " [ 0.6187291 ]\n",
      " [ 0.62541806]\n",
      " [ 0.63210702]\n",
      " [ 0.63879599]\n",
      " [ 0.64548495]\n",
      " [ 0.65217391]\n",
      " [ 0.65886288]\n",
      " [ 0.66555184]\n",
      " [ 0.6722408 ]\n",
      " [ 0.67892977]\n",
      " [ 0.68561873]\n",
      " [ 0.69230769]\n",
      " [ 0.69899666]\n",
      " [ 0.70568562]\n",
      " [ 0.71237458]\n",
      " [ 0.71906355]\n",
      " [ 0.72575251]\n",
      " [ 0.73244147]\n",
      " [ 0.73913043]\n",
      " [ 0.7458194 ]\n",
      " [ 0.75250836]\n",
      " [ 0.75919732]\n",
      " [ 0.76588629]\n",
      " [ 0.77257525]\n",
      " [ 0.77926421]\n",
      " [ 0.78595318]\n",
      " [ 0.79264214]\n",
      " [ 0.7993311 ]\n",
      " [ 0.80602007]\n",
      " [ 0.81270903]\n",
      " [ 0.81939799]\n",
      " [ 0.82608696]\n",
      " [ 0.83277592]\n",
      " [ 0.83946488]\n",
      " [ 0.84615385]\n",
      " [ 0.85284281]\n",
      " [ 0.85953177]\n",
      " [ 0.86622074]\n",
      " [ 0.8729097 ]\n",
      " [ 0.87959866]\n",
      " [ 0.88628763]\n",
      " [ 0.89297659]\n",
      " [ 0.89966555]\n",
      " [ 0.90635452]\n",
      " [ 0.91304348]\n",
      " [ 0.91973244]\n",
      " [ 0.9264214 ]\n",
      " [ 0.93311037]\n",
      " [ 0.93979933]\n",
      " [ 0.94648829]\n",
      " [ 0.95317726]\n",
      " [ 0.95986622]\n",
      " [ 0.96655518]\n",
      " [ 0.97324415]\n",
      " [ 0.97993311]\n",
      " [ 0.98662207]\n",
      " [ 0.99331104]\n",
      " [ 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "x_data = np.linspace(-1,1,300)[:, np.newaxis]# 生成300个数据，并将其变成2维数组\n",
    "print(np.linspace(-1,1,300))\n",
    "print(x_data)\n",
    "noise = np.random.normal(0, 0.05, x_data.shape)\n",
    "y_data = np.square(x_data) - 0.5 + noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义节点准备接收数据\n",
    "\n",
    "在 TensorFlow 中用placeholder 来描述等待输入的节点，需要指定类型。\n",
    "\n",
    "在执行节点的时候用一个字典“喂”这些节点。相当于先把变量 hold 住，然后每次从外部传入data，注意 placeholder 和 feed_dict 是绑定用的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Placeholder_2:0\", shape=(?, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# define placeholder for inputs to network  \n",
    "xs = tf.placeholder(tf.float32, [None, 1])\n",
    "ys = tf.placeholder(tf.float32, [None, 1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义隐藏层和预测层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Relu_2:0\", shape=(?, 10), dtype=float32)\n",
      "Tensor(\"add_11:0\", shape=(?, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# add hidden layer 输入值是 xs，在隐藏层有 10 个神经元   \n",
    "l1 = add_layer(xs, 1, 10, activation_function=tf.nn.relu)\n",
    "print(l1)\n",
    "# add output layer 输入值是隐藏层 l1，在预测层输出 1 个结果\n",
    "prediction = add_layer(l1, 10, 1, activation_function=None)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the error between prediciton and real data    \n",
    "loss = tf.reduce_mean(tf.reduce_sum(tf.square(ys - prediction),\n",
    "                     reduction_indices=[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 选择 optimizer 使 loss 达到最小    \n",
    "\n",
    "这里选择梯度下降（ Gradient Descent）这个最基本的优化器（ Optimizer）。\n",
    "\n",
    "神经网络的核心思想是让损失达到最小，所以训练步骤被直接定义为利用优化器使误差最小。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\pythonspace\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "# 这一行定义了用什么方式去减少 loss，学习率是 0.1       \n",
    "train_step = tf.train.GradientDescentOptimizer(0.1).minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 对所有变量进行初始化、调整\n",
    "\n",
    "经过前面的定义，下面在运行模型前要初始化所有变量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\pythonspace\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\tf_should_use.py:193: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "0.12465158\n",
      "0.011637847\n",
      "0.0074542393\n",
      "0.0060863076\n",
      "0.005356229\n",
      "0.004768065\n",
      "0.004239615\n",
      "0.0038120167\n",
      "0.0034752993\n",
      "0.0032102198\n",
      "0.0030381908\n",
      "0.0029247121\n",
      "0.0028487167\n",
      "0.0027858324\n",
      "0.002737039\n",
      "0.0026898677\n",
      "0.0026525361\n",
      "0.0026250172\n",
      "0.0026020193\n",
      "0.002575664\n"
     ]
    }
   ],
   "source": [
    "init = tf.initialize_all_variables()\n",
    "sess = tf.Session()\n",
    "# 上面定义的都没有运算，直到 sess.run 才会开始运算\n",
    "sess.run(init)\n",
    "\n",
    "# 迭代 1000 次学习，sess.run optimizer\n",
    "for i in range(1000):\n",
    "    # training train_step 和 loss 都是由 placeholder 定义的运算，所以这里要用 feed 传入参数\n",
    "    sess.run(train_step, feed_dict={xs: x_data, ys: y_data})\n",
    "    if i % 50 == 0:\n",
    "        # 每50步打印输出一次，查看优化结果：损失函数的大小\n",
    "        print(sess.run(loss, feed_dict={xs: x_data, ys: y_data}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
