{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 神经网络与tensorflow\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tensorflow介绍\n",
    "\n",
    "TensorFlow 是一个用于人工智能的开源神器。\n",
    "\n",
    "TensorFlow是一个采用数据流图（data flow graphs），用于数值计算的开源软件库。\n",
    "\n",
    "它灵活的架构让你可以在多种平台上展开计算，例如台式计算机中的一个或多个CPU（或GPU），服务器，移动设备等等。\n",
    "\n",
    "TensorFlow 最初由Google大脑小组的研究员和工程师们开发出来，用于机器学习和深度神经网络方面的研究，但这个系统的通用性使其也可广泛用于其他计算领域。\n",
    "\n",
    "\n",
    "使用 TensorFlow, 你必须明白 TensorFlow:\n",
    "\n",
    "- 使用图 (graph) 来表示计算任务；\n",
    "- 图中的节点被称为op（operation）；\n",
    "- 在被称之为 会话 (Session) 的上下文 (context) 中执行图；\n",
    "- 使用 tensor (也叫张量、数组)表示数据；\n",
    "- 每个tensor是一个类型化的多维数组；\n",
    "  + 例如, 你可以将一小组图像集表示为一个四维浮点数数组, 这四个维度分别是[batch, height, width, channels].\n",
    "  \n",
    "- 一个节点可以获得0个或多个tensor（数据）进行计算，产生0或多个tensor;\n",
    "- 通过变量 (Variable) 维护状态.\n",
    "- 使用 feed 和 fetch 可以为任意的操作(arbitrary operation) 赋值或者从其中获取数据.\n",
    "\n",
    "\n",
    "\n",
    "一个 TensorFlow 图描述了计算的过程. 为了进行计算, 图必须在会话里被启动。\n",
    "\n",
    "会话将图的 op 分发到诸如 CPU 或 GPU 之类的设备上, 同时提供执行 op 的方法. 这些方法执行后, 将产生的 tensor 返回。\n",
    "\n",
    "在 Python 语言中, 返回的 tensor 是 numpy ndarray 对象。\n",
    "\n",
    "让我们先看一段使用 Python API 撰写的 TensorFlow 示例代码, 对将要学习的内容有初步的印象.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用 tensorflow 实现神经网络学习器的过程\n",
    "\n",
    "1. 准备数据;\n",
    "2. 定义节点准备接收数据;\n",
    "3. 定义隐藏层和输出层；\n",
    "4. 定义损失函数；\n",
    "5. 选定优化器，设定训练方法（使损失最小化）；\n",
    "6. 对所有变量进行初始化，在会话中运行优化器，迭代1000次进行反馈学习。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义神经网络层的构建方法\n",
    "\n",
    "用tf.Variable定义变量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# 先写一个添加层的函数（可以一会儿再理解它）\n",
    "def add_layer(inputs, in_size, out_size, activation_function=None):\n",
    "    # 增加一个以上的层，并返回该层的输出。\n",
    "    # 下面定义了神经元相关的权重、阈值、激活函数 \n",
    "    Weights = tf.Variable(tf.random_normal([in_size, out_size]))# 初始化连接权重\n",
    "    biases = tf.Variable(tf.zeros([1, out_size]) + 0.1)# 初始化阈值\n",
    "    Wx_plus_b = tf.matmul(inputs, Weights) + biases #matmul指矩阵乘法,这里实际上定义了前向传播过程\n",
    "    if activation_function is None:\n",
    "        outputs = Wx_plus_b\n",
    "    else:\n",
    "        outputs = activation_function(Wx_plus_b)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 准备数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = np.linspace(-1,1,300)[:, np.newaxis]# 生成300个数据，并将其变成2维数组\n",
    "noise = np.random.normal(0, 0.05, x_data.shape)\n",
    "y_data = np.square(x_data) - 0.5 + noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义节点准备接收数据\n",
    "\n",
    "在 TensorFlow 中用placeholder 来描述等待输入的节点，需要指定类型。\n",
    "\n",
    "在执行节点的时候用一个字典“喂”这些节点。相当于先把变量 hold 住，然后每次从外部传入data，注意 placeholder 和 feed_dict 是绑定用的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define placeholder for inputs to network  \n",
    "xs = tf.placeholder(tf.float32, [None, 1])\n",
    "ys = tf.placeholder(tf.float32, [None, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义隐藏层和预测层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add hidden layer 输入值是 xs，在隐藏层有 10 个神经元   \n",
    "l1 = add_layer(xs, 1, 10, activation_function=tf.nn.relu)\n",
    "# add output layer 输入值是隐藏层 l1，在预测层输出 1 个结果\n",
    "prediction = add_layer(l1, 10, 1, activation_function=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the error between prediciton and real data    \n",
    "loss = tf.reduce_mean(tf.reduce_sum(tf.square(ys - prediction),\n",
    "                     reduction_indices=[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 选择 optimizer 使 loss 达到最小    \n",
    "\n",
    "这里选择梯度下降（ Gradient Descent）这个最基本的优化器（ Optimizer）。\n",
    "\n",
    "神经网络的核心思想是让损失达到最小，所以训练步骤被直接定义为利用优化器使误差最小。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这一行定义了用什么方式去减少 loss，学习率是 0.1       \n",
    "train_step = tf.train.GradientDescentOptimizer(0.1).minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 对所有变量进行初始化、调整\n",
    "\n",
    "经过前面的定义，下面在运行模型前要初始化所有变量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.90379447\n",
      "0.023425106\n",
      "0.008540405\n",
      "0.005533939\n",
      "0.0047564385\n",
      "0.004226727\n",
      "0.0039068772\n",
      "0.0037330973\n",
      "0.003620305\n",
      "0.0035491674\n",
      "0.0034944979\n",
      "0.0034243346\n",
      "0.0033819024\n",
      "0.0033533971\n",
      "0.0033129738\n",
      "0.0032618728\n",
      "0.0032105844\n",
      "0.0031465753\n",
      "0.0030816204\n",
      "0.0030348361\n"
     ]
    }
   ],
   "source": [
    "init = tf.initialize_all_variables()\n",
    "sess = tf.Session()\n",
    "# 上面定义的都没有运算，直到 sess.run 才会开始运算\n",
    "sess.run(init)\n",
    "\n",
    "# 迭代 1000 次学习，sess.run optimizer\n",
    "for i in range(1000):\n",
    "    # training train_step 和 loss 都是由 placeholder 定义的运算，所以这里要用 feed 传入参数\n",
    "    sess.run(train_step, feed_dict={xs: x_data, ys: y_data})\n",
    "    if i % 50 == 0:\n",
    "        # 每50步打印输出一次，查看优化结果：损失函数的大小\n",
    "        print(sess.run(loss, feed_dict={xs: x_data, ys: y_data}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
