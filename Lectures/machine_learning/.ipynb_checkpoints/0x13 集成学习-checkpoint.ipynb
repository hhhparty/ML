{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 集成学习\n",
    "\n",
    "本文主要参考周志华教授的著作《机器学习》"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 个体与集成\n",
    "\n",
    "**集成学习（ensemble learning）通过构建并结合多个学习器来完成学习任务**，有时也被称为多分类器系统（multi-classifier system）、基于委员会的学习（committee-based learning）。\n",
    "\n",
    "下图显示出集成学习的一般结构：\n",
    "\n",
    "![集成学习示意图](images/ensemblelearning/集成学习示意图.png)\n",
    "\n",
    "- 先产生一组“个体学习器”（individual learner）；\n",
    "- 再用某种策略将它们结合起来。\n",
    "\n",
    "个体学习器通常有一个现有的学习算法从训练数据产生，例如C4.5决策树算法、BP神经网络算法等，此时集成中只包含同种类型的个体学习器。例如“决策树集成”中全是决策树，“神经网络集成”中全是神经网络，**这样的集成是“同质”的（homogeneous）。**\n",
    "\n",
    "同质集成中的个体学习器亦称为**“基学习算法”（base learning algorithm）。**\n",
    "\n",
    "集成也可包含不同类型的个体学习器，例如同时半酣决策树和神经网络，这样的集成是**“异质集成”（heterogeneous）**。\n",
    "\n",
    "异质集成中的个体学习器由不同的学习算法生成，这时九不再由基学习算法；相应地，个体学习器一般不称为基学习器，常称为**“组件学习器”（component learner）**或称为个体学习器。\n",
    "\n",
    "**集成学习通过将多个学习器进行结合，常可获得比单一学习器显著优秀的泛化性能。**\n",
    "\n",
    "这对“弱学习器（weak learning）”尤为明显，因此集成学习的很多理论研究都是针对弱学习器进行的，而基学习器有时也被直接称为弱学习器。\n",
    "\n",
    "> 弱学习器常指泛化性能略优于随机猜测的学习器，例如二分类问题上精度略高于50%的分类器\n",
    "\n",
    "虽然，理论上使用弱学习器集成足以获得好的性能，但在实践中出于种种考虑，人们往往会使用比较强的学习器。\n",
    "\n",
    "一般情况下，好坏参杂时得到的结果会比坏的好一点，好的差一点，那么集成学习是怎么获得好性能的？\n",
    "\n",
    "事实上，集成学习中的个体学习器要“好而不同”，即个体学习器要有一定的“准确性”，不能太坏，并且要有“多样性”（diversity），即学习器间具有差异。\n",
    "\n",
    "下面做简单的分析：\n",
    "\n",
    "考虑二分类问题$ y \\in \\{ -1,+1\\}$和真实函数f，假定基分类器的错误率为$\\epsilon$，即对每个基分类器$h_i$有：\n",
    "\n",
    "$P(h_i(x) \\neq f(x)) = \\epsilon $  ——式（1）\n",
    "\n",
    "假设集成通过简单投票法结合T（为讨论简单，T为奇数）个基分类器，若有超过半数的基分类器正确，则集成分类就正确：\n",
    "\n",
    "$H(x) = sign(\\sum_{i=1}^{T}h_i(x))$ ——式（2）\n",
    "\n",
    "假定基分类器的错误率为相互独立，则由Hoeffding不等式可知，集成的错误率为：\n",
    "\n",
    "$P(H(x) \\neq f(x)) = \\sum_{k=0}^{\\lfloor T/2 \\rfloor}(_k^T)(1-\\epsilon)^k \\epsilon ^{T-k} \\leq exp(-\\frac{1}{2}T(1-2\\epsilon)^2)$ ——式（3）\n",
    "\n",
    "上式显示出，**随着集成中个体分类器数目T的增大，继承的错误率将指数级下降，最终趋向于零。**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然而我们必须注意到，**上面的分析有一个关键假设：基学习器的误差相互独立。**\n",
    "\n",
    "在现实任务中，个体学习器是为解决同一个问题训练出来的，它们显然不可能相互独立！\n",
    "\n",
    "事实上，个体学习器的“准确性”和“多样性”本身就存在冲突。一般的，准确性很高之后，要增加多样性就需要牺牲准确性。事实上，**如何产生并结合“好而不同”的个体学习器，恰是集成学习研究的核心。**\n",
    "\n",
    "根据个体学习器的生成方式，目前的集成学习方法大致可以分类两类：\n",
    "\n",
    "- 个体学习器间存在强依赖关系、必须串行生成的序列化方法；\n",
    "- 个体学习器间不存在强依赖关系、可同时生成的并行化方法。\n",
    "\n",
    "前者的代表是Boosting，后者的代表是Bagging和随机森林（Random Forest）。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boosting\n",
    "\n",
    "Boosting是一组可将弱学习器提升为强学习器的算法。\n",
    "\n",
    "这族算法的工作机制类似：\n",
    "\n",
    "- 先从初始训练集训练出一个基学习器；\n",
    "- 再根据基学习器的表现对训练样本分布进行调整，使得先前基学习器做错的训练样本在后续受到更多关注；\n",
    "- 然后基于调整后的样本分布来训练下一个基学习器；\n",
    "- 如此重复进行，直至基学习器数目达到事先指定的值T；\n",
    "- 最终，将这T个基学习器进行加权结合。\n",
    "\n",
    "Boosting族算法最著名的代表是AdaBoost[Freund and Schapire, 1997]，其描述如下图所示，其中$ y \\in \\{ -1,+1\\}$，f是真实函数。\n",
    "\n",
    "![AdaBoost算法](images/ensemblelearning/adaboost算法.PNG)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AdaBoost算法有多种推导方式，比较容易理解的是基于“加性模型”（additive model），即基学习器的线性组合：\n",
    "\n",
    "$H(x) = \\sum_{t=1}^{T}\\alpha_t h_t (x)$ ——式（4）\n",
    "\n",
    "来最小化指数损失函数（exponential loss function）[Friedman et al. 2000]：\n",
    "\n",
    "$l_{exp}(H|D) = E_{x \\sim D}[e^{-f(x)H(x)}]$ ——式（5）\n",
    "\n",
    "> 注：$E_{x \\sim D}(\\centerdot)$ 的含义解释，D为概率分布，$x \\sim D$可简单理解为在数据集D中进行一次随机抽样，每个样本被取到的概率；$E_{x \\sim D}(\\centerdot)$ 为经典的期望，可简单理解为对数据集D以概率$P(\\centerdot|x)$进行加权后的期望。\n",
    "\n",
    "由于$f(x) \\in \\{-1,1\\}$，所以$l_{exp}(H|D) = E_{x \\sim D}[e^{-f(x)H(x)}] = P(f(x) =1|x)e^{-H(x)} + P(f(x) = -1|x)e^{H(x)} $\n",
    "\n",
    "若H(x)能令指数损失函数最小化，则考虑式（5）对H(x)的偏导：\n",
    "\n",
    "$\\frac{\\partial l_{exp}(H|D)}{\\partial H(x)} = - e^{-H(x)}P(f(x) = 1|x) + e^{H(x)P(f(x) = -1|x}$ ——式（6）\n",
    "\n",
    "令式（6）为零，可解得：\n",
    "\n",
    "$ H(x) = \\frac{1}{2}ln \\frac{P(f(x) = 1 |x)}{P(f(x) = - 1 |x)}$ ——式（7）\n",
    "\n",
    "因此，有\n",
    "\n",
    "$$\n",
    "sign(H(x)) = sign( \\frac{1}{2}ln \\frac{P(f(x) = 1 |x)}{P(f(x) = - 1 |x)} )=\n",
    " \\left \\{\n",
    " \\begin{matrix}\n",
    "   1, P(f(x) = 1 |x) > P(f(x) = -1 |x) ;\\\\\n",
    "   -1, P(f(x) = 1 |x) < P(f(x) = -1 |x) ;\\\\\n",
    "  \\end{matrix}\n",
    "  \\right . = argmax_{y \\in \\{-1,1\\}}P(f(x) = y |x)  —— 式(8)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这意味着sign(H(x))达到了贝叶斯最优错误率。\n",
    "\n",
    "换言之，若指数函数最小化，则分类错误率也将最小化。\n",
    "\n",
    "这说明指数损失函数式分类任务原本0/1损失函数的一致的（consistent）替代函数。\n",
    "\n",
    "> 损失函数的知识，可参考https://www.cnblogs.com/hejunlin1992/p/8158933.html\n",
    "\n",
    "> 公式推导问题，可以参考https://github.com/datawhalechina/pumpkin-book\n",
    "\n",
    "由于这个替代函数有更好的数学性质，例如它是连续可微函数，因此我们呢可用它替代0/1损失函数作为优化目标。\n",
    "\n",
    "在AdaBoost算法中，第一个基分类器$h_1$是通过直接将基学习算法用于初始数据分布而得；此后迭代生成$h_t$和$\\alpha_t$基于分布$D_t$产生后，该基分类器的权重$\\alpha_t$应使得$\\alpha_t h_t$最小化指数损失函数：\n",
    "\n",
    "$ l_{exp}(\\alpha_t h_t|D_t) = E_{x \\sim D_t}[e^{-f(x)\\alpha_t h_t(x)}] \\\\ \\quad\\quad\\quad\\quad = E_{x \\sim D_t}[e^{-f(x)\\alpha_t h_t(x)}] \\\\ \\quad\\quad\\quad\\quad =  E_{x \\sim D_t}[e^{-\\alpha_t}Ⅱ(f(x) = h_t(x)) + e^{\\alpha_t}Ⅱ(f(x) \\neq h_t(x))]   \\\\ \\quad\\quad\\quad\\quad = e^{-\\alpha_t}P_{x \\in D_t} (f(x) = h_t(x)) +e^{\\alpha_t}P_{x \\in D_t} (f(x)\\neq h_t(x))  \\\\ \\quad\\quad\\quad\\quad = e^{\\alpha_t}(1-\\epsilon_t) + e^{\\alpha_t}\\epsilon_t ,   \\quad\\quad\\quad\\quad ——式（9）$                      \n",
    "\n",
    "其中$\\epsilon_t = P_{x \\in D_t}(h_t(x) \\neq f(x))$。\n",
    "\n",
    "考虑指数损失函数得导数：\n",
    "\n",
    "$\\frac{\\partial l_{exp} \\ \\ (\\alpha_t h_t|D_t)}{\\partial \\alpha_t} = -e^{-\\alpha_t}(1 -\\epsilon_t)+ e^{\\alpha_t}\\epsilon_t$  ——式（10）\n",
    "\n",
    "令式（10）为零可解得：\n",
    "\n",
    "$\\alpha_t = \\frac{1}{2} ln(\\frac{1-\\epsilon_t}{\\epsilon_t})$ ——式（11）\n",
    "\n",
    "这恰是上文中算法第6行得分类器权重更新公式。\n",
    "\n",
    "AdaBoost算法在获得$H_{t-1}$之后样本分布将进行调整，使下一轮得基学习器$h_t$能纠正$H_{t-1}$的一些错误。理想的$h_t$能纠正$H_{t-1}$的全部错误，即最小化：\n",
    "\n",
    "$l_{exp}(H_{t-1} +h_t|D) = E_{x \\sim D}[e^{-f(x)(H_{t-1 \\ }(x) + h_t(x)}]= E_{x \\sim D}[e^{-f(x)H_{t-1 \\ }(x)}e^{-f(x) h_t(x)}]$ ——式（12）\n",
    "\n",
    "注意到$f^2(x) = h_t^2(x) = 1$，式（12）可使用$e^{-f(x)h_t(x)}$的泰勒展开式近似为：\n",
    "\n",
    "$l_{exp}(H_{t-1} + h_t |D) \\simeq E_{x \\sim D} [e^{-f(x)H_{t-1 \\ }(x)}(1-f(x)h_t(x)+\\frac{f^2(x)h_t^2(x))}{2})] \\\\ =E_{x \\sim D} [e^{-f(x)H_{t-1 \\ }(x)}(1-f(x)h_t(x)+\\frac{1}{2})] $  ——式（13）\n",
    "\n",
    "> 注，泰勒公式有$e^x = 1+\\frac{1}{1!}x+\\frac{1}{2!}x^2 +\\frac{1}{3!}x^3 +o(x^3)$\n",
    "\n",
    "于是，理想的学习器：\n",
    "\n",
    "$h_t(x) = argmin_h l_{exp}(H_{t-1} +h |D) \\\\ = argmin_h E_{x \\sim D}[e^{-f(x)H_{t-1 \\ }(x)}(1-f(x)h_t(x)+\\frac{1}{2})] \\\\ = argmin_h E_{x \\sim D}[e^{-f(x)H_{t-1 \\ }(x)}f(x)h_t(x)] \\\\ = argmin_h E_{x \\sim D}[\\frac{e^{-f(x)H_{t-1}(x)}}{E_{x \\sim D }[e^{-f(x )H_{t-1 }(x)} ]}f(x)h(x) ]$  ——式（14）\n",
    "\n",
    "注意到$E_{x \\sim D }[e^{-f(x )H_{t-1 }(x)} ]$是一个常数（因为这是前t-1个学习器的期望损失函数，其值已确定，为某个常数）。令$D_t$表示一个分布：\n",
    "\n",
    "$D_t(x) = \\frac{D(x)e^{-f(x)H_{t-1}(x)}}{E_{x \\sim D }[e^{-f(x )H_{t-1 }(x)} ]}$ ——式（15）\n",
    "\n",
    "则根据数学期望的定义，这等价于令：\n",
    "\n",
    "$h_t(x) = argmax_h E_{x \\sim D}[\\frac{e^{-f(x)H_{t-1}(x)}}{ E_{x \\sim D}[e^{-f(x )H_{t-1 }(x)} ]}f(x)h(x)] = argmax_h E_{x \\sim D}[f(x)h(x)$ ——式（16）\n",
    "\n",
    "> 数学期望的定义：离散型随机变量的一切可能的取值$x_i$与对应的概率$p(x_i)$乘积之和称为该离散型随机变量的数学期望$E(X) = \\sum_{i=1}^N x_ip_i$.\n",
    "> 对于连续型随机变量，连续性随机变量X的概率密度函数为f(x)，若积分绝对收敛，则随机变量X的数学期望 $E(X) = \\int_{i=1}^{\\infty}f(x)xdx$\n",
    "\n",
    "> 在本书中，概率分布为$D(x)$，所以$E_{x \\sim D}[e^{-f(x)H(x)}] = \\sum_{i=1}^{|D|}D(x_i)e^{-f(x_i)H(x_i)}$\n",
    "\n",
    "由$f(x),h(x) \\in \\{-1,+1\\}$,有\n",
    "\n",
    "$f(x)h(x) = 1 -2 Ⅱ(f(x) \\neq h(x))$  ——式（17）\n",
    "\n",
    "则理想的基学习器：\n",
    "\n",
    "$h_t(x) = argmin_h E_{x \\sim D_t}[Ⅱ(f(x) \\neq h(x))]$  ——式（18）\n",
    "\n",
    "由此可见，理想的$h_t$将在分布$D_t$下最小化分类误差。因此，若分类器将基于分布$D_t$来训练，且针对$D_t$的分类误差应小于0.5。\n",
    "\n",
    "这在一定程度上类似“残差逼近”的思想。考虑到$D_t$和$D_{t+1}$的关系，有：\n",
    "\n",
    "$D_{t+1}(x) = \\frac{D(x)e^{-f(x)H_t(x)}}{E_{x \\sim D}[e^{-f(x)H_t(x)}]} \\\\  = \\frac{D(x)e^{-f(x)H_{t-1}(x)}e^{-f(x)\\alpha_th_t(x)}}{E_{x \\sim D}[e^{-f(x)H_t(x)}]} \\\\  = D_t(x) e^{-f(x)\\alpha_th_t(x)} \\frac{E_{x \\sim D}[e^{-f(x)H_{t-1}(x)}]}{E_{x \\sim D}[e^{-f(x)H_t(x)}]}$  ——式（19）\n",
    "\n",
    "这恰是上述算法中第7行的样本分布更新公式。\n",
    "\n",
    "于是，由式（11）和（19）可见，我们从基于加性模型迭代优化指数损失函数的角度推导出了图8.3的AdaBoost算法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "。。。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging 与随机森林\n",
    "\n",
    "由之前的综述可知，欲得到泛化性能强的集成，集成中的个体学习器应尽可能相互独立；虽然“独立”在现实任务中无法做到，但可以设法使基学习器尽可能具有较大差异。\n",
    "\n",
    "给定一个训练数据集，一种可能的做法是对训练样本进行采样，产生出若干个不同的子集，再从每个数据子集中训练出一个基学习器。\n",
    "\n",
    "然而，为了活得好的集成，我们同时还希望个体学习器不能太差。如果采样出的每个子集都完全不同，则每个基学习器只用到了一小部分训练数据，甚至不足以进行有效学习，这显然无法确保产生出比较好的基学习器。\n",
    "\n",
    "为了解决上述问题，我们可以考虑使用相互有交叠的采样子集。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging\n",
    "\n",
    "Bagging是并行式集成学习方法最著名的代表。从名字可以看出，它基于自助采样法（bootstrap sampling）。\n",
    "\n",
    "给定包含m个样本的数据集，我们先随机取出一个样本放入采样集中，再把样本放回初始数据集，使得下次采样时该样本仍有可能被选中，这样，经过m次随机采样操作，我们得到含m个样本的采样集，初始训练集中有的样本在采样集里多次出现，有的则从未出现。根据自助采样法中的讨论，初始训练集中约有63.2%的样本出现在采样集中。\n",
    "\n",
    "照这样，我们可采样出T个含m个训练样本的采样集，然后基于每个采样集训练出一个基学习器，再将这些基学习器进行组合。这就是Bagging的基本流程。\n",
    "\n",
    "再对预测输出进行结合时，Baging通常对分类任务使用简单投票法（少数服从多数),对回归任务使用简单平均法。\n",
    "\n",
    "若分类预测时出现两个类收到同样票数的情形，则最简单的做法就是随机选择一个，也可进一步考查学习器投票的置信度来确定最终胜者。\n",
    "\n",
    "![Bagging算法](images/ensemblelearning/Bagging算法.PNG)\n",
    "\n",
    "假定基学习器的计算复杂度为O(m),则Bagging的复杂度大致为$T(O(m) + O(s)$，考虑到采样与投票/平均过程的复杂度$O(s)$很小，而T通常是一个不太大的常数，因此训练一个Baaging集成与直接使用基学习器算法训练一个学习器的复杂度同阶，这说明Bagging是一个很高效的集成学习算法。另外，与标准AdaBoost只适用于二分类任务不同，Bagging能不经修改的用于分类、回归任务。\n",
    "\n",
    "值得一提的是，自助采用过程还给Bagging带来了另一个优点：由于每个基学习器只使用了初始训练集中的约63.2%的样本，剩下约36.8%的样本可用作验证集来对泛化性能进行“包外估计”（out-of-bag estimate）。为此需记录每个基学习器所使用的训练样本。\n",
    "\n",
    "\n",
    ".\n",
    "。。。.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 随机森林\n",
    "\n",
    "随机森林（Random Forest）是Bagging的一个扩展变体。RF在以决策树为基学习器构建Bagging集成的基础上，进一步在决策树的训练过程中引入了随机属性选择。\n",
    "\n",
    "具体来说，传统决策树在选择划分属性时是在当前节点的属性集合（假定有d个属性）中选择一个最优属性；\n",
    "\n",
    "而在RF中，对基决策树的每个节点，先从该节点的属性集合中随机选择一个包含k个属性的子集，然后再从这个子集中选择一个最优属性用于划分。这里的参数k控制了随机性的引入程度：若令k = d，则及决策树的构建与传统决策树相同；若令k=1，则是随机选择一个属性用于划分；一般情况下，推荐$k=log_2d$。\n",
    "\n",
    "随机森林简单、容易实现、计算开销小，令人惊奇的是，它在很多现实任务中展现出强大的学习性能，被誉为“代表集成学习技术水平的方法”。\n",
    "\n",
    "可以看出，随机森林对Bagging只做了小改动，但是与Bagging中基学习器的“多样性”仅通过样本扰动（对初始训练集采样）而不同，随机森林中基学习器不仅来自样本扰动，还来自属性扰动，这就使得最终集成的泛化性能可通过个体学习器之间的差异度的增加而进一步提升。\n",
    "\n",
    "随机森林的收敛性与Bagging相似。下图所示，随机森林的起始性能往往相对较差，特别是集成中只包含一个基学习器时。\n",
    "\n",
    "![在两个UCI数据上集成规模对随机森林与Bagging的影响](images/ensemblelearning/在两个UCI数据上集成规模对随机森林与Bagging的影响.PNG)\n",
    "\n",
    "这很容易理解，因为通过引入属性扰动，随机森林中个体学习器的性能往往有所降低。然而，随着个体学习器数目的增加，随机森林通常会收敛到更低的泛化误差。值得一提的是，随机森林的训练效率常优于Bagging，因此在个体决策树的构建过程中，Bagging使用的是“确定性”决策树，在选择划分属性时要对结点的所有属性进行考察，而随机网络使用的是“随机性”决策树，则只需考察一个属性的子集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
