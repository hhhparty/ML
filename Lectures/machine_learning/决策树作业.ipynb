{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 张三1000-决策树作业\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 计算信息熵和信息增益"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('纹理', 0.3805918973682686)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"计算香农信息熵的python程序代码\n",
    "\"\"\"\n",
    "from math import log\n",
    "from sklearn import neighbors,datasets\n",
    "import pandas as pd\n",
    "\n",
    "def calcShannonEnt(dataFrame):\n",
    "    \"\"\"\n",
    "    功能：根据分类标记，计算某数据集的信息熵。\n",
    "    输入：dataFrame，使用pandas.seriers类型给出的含有标记的数据集，标记信息为最后一列\n",
    "    输出：shannonEnt，数据集按当前标记分类结果的信息熵值\n",
    "    \n",
    "    \"\"\"  \n",
    "    numEntries = dataFrame.shape[0] #s数据集示例数\n",
    "    \n",
    "    labelCounts = {} #定义字典，键为分类标记名，值为标记的计数值\n",
    "    labelCounts.update(dataFrame.iloc[:,-1].value_counts())#为字典赋值,认为数据集最后一列为label\n",
    "    \n",
    "    shannonEnt = 0.0  # 设置香农信息熵初值为0.0\n",
    "    for key in labelCounts:\n",
    "        # 按公式求信息熵值\n",
    "        prob = float(labelCounts[key])/numEntries\n",
    "        \n",
    "        shannonEnt -= prob * log(prob,2)    # 求以2为底的对数。\n",
    "    return shannonEnt\n",
    "\n",
    "\n",
    "\n",
    "def calcInforGain(df,aFeature):\n",
    "    \"\"\"\n",
    "    功能：按照上述公式计算用属性aFeature对样本集dataframe进行划分的信息增益。\n",
    "    输入：数据集dataFrame；\n",
    "          划分属性名aFeature；\n",
    "    输出：（最好划分属性名称，最大信息增益值）\n",
    "    \"\"\"\n",
    "    # 统计数据集的样本数量\n",
    "    totalsampleCount = df.shape[0]\n",
    "    # 统计属性a各值对应的样本数量\n",
    "    sampleCounts = {} \n",
    "    sampleCounts.update(df[aFeature].value_counts())\n",
    "    #print(sampleCounts)\n",
    "    infogain = calcShannonEnt(df)\n",
    "    for key,value in sampleCounts.items():\n",
    "        subdf = df[df[aFeature] == key]\n",
    "        infogain -= subdf.shape[0]/ totalsampleCount * calcShannonEnt(subdf)\n",
    "    return infogain\n",
    "\n",
    "def getBestDivideFeature(df):    \n",
    "    featureInfoGains = {}    \n",
    "    for colname in df.columns[:-1]:\n",
    "        # 对非标记属性，计算其信息增益，标记属性为dataframe中最后一列\n",
    "        infogain = calcInforGain(df,colname)\n",
    "        featureInfoGains[colname] = infogain\n",
    "    # 对已计算增益的结果进行排序\n",
    "    bestFeature = sorted(featureInfoGains.items(),key =lambda item:item[1],reverse=True)[0]\n",
    "    #print(featureInfoGains)\n",
    "    return bestFeature\n",
    "\n",
    "#dataframe = pd.read_csv(\"data/vote/VoteTraining-cn.csv\",header=0,sep=',')        \n",
    "#getBestDivideFeature(dataframe)    \n",
    "dataframe = pd.read_csv(\"data/maloon/maloon2.txt\",header=0,sep=',')        \n",
    "getBestDivideFeature(dataframe.iloc[:,1:])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建决策树结点类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type:root,Label:None,Samples:[],Children:['middle[a=1]', 'middle[a=2]'] \n",
      "\tType:middle,Label:None,Samples:[],Children:['leaf[b=1]', 'leaf[b=2]'] \n",
      "\t\tType:leaf,Label:None,Samples:[],Children:[] \n",
      "\t\tType:leaf,Label:None,Samples:[],Children:[] \n",
      "\tType:middle,Label:None,Samples:[],Children:[] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "class Node:\n",
    "    \"\"\"决策树结点类\"\"\"\n",
    "    def __init__(self):\n",
    "        self._type = None\n",
    "        self._label = None\n",
    "        self._samples = pd.DataFrame()\n",
    "        self._children = {}        \n",
    "    \n",
    "    @property    \n",
    "    def type(self):\n",
    "        return self._type\n",
    "    \n",
    "    @type.setter\n",
    "    def setType(self,type):\n",
    "        self._type = type\n",
    "    \n",
    "    @property    \n",
    "    def label(self):\n",
    "        return self._label\n",
    "    \n",
    "    @label.setter\n",
    "    def setLabel(self,label):\n",
    "        self._label = label\n",
    "        \n",
    "    @property\n",
    "    def samples(self):\n",
    "        return self._samples\n",
    "    \n",
    "    @samples.setter\n",
    "    def setSamples(self,samples):\n",
    "        if isinstance(samples, pd.DataFrame):\n",
    "            self._samples = samples\n",
    "    \n",
    "    @property    \n",
    "    def children(self):\n",
    "        return self._children\n",
    "    \n",
    "\n",
    "    def addChildren(self,key,children):\n",
    "        self._children[key] = children\n",
    "\n",
    "    def getChildrenTypeList(self):\n",
    "        cl = []\n",
    "        for k,v in self._children.items():\n",
    "            cl.append(v.type + '['+k+']')\n",
    "        return cl\n",
    "    \n",
    "    def __str__(self):        \n",
    "        return \"Type:{},Label:{},Samples:{},Children:{} \".format(\n",
    "                self._type,self._label,\n",
    "                self._samples.index.tolist(),\n",
    "                self.getChildrenTypeList())\n",
    "\n",
    "def bfs(rootNode,depth = 0):\n",
    "    print(\"{}{}\".format('\\t'*depth,rootNode))\n",
    "    #print(\"Type:{},Label:{},Samples:{}\".format(rootNode.type,rootNode.label,rootNode.samples.index.tolist()))\n",
    "    for k,v in rootNode.children.items():\n",
    "        bfs(v,depth + 1)\n",
    "    return depth\n",
    "                \n",
    "node = Node()\n",
    "node.setType = 'root' \n",
    "child = Node()\n",
    "node.addChildren('a=1',child)\n",
    "child.setType = 'middle'\n",
    "child2 = Node()\n",
    "node.addChildren('a=2',child2)\n",
    "child2.setType = 'middle'\n",
    "ss = Node()\n",
    "ss.setType = 'leaf'\n",
    "ss1 = Node()\n",
    "ss1.setType = 'leaf'\n",
    "child.addChildren('b=1',ss)\n",
    "child.addChildren('b=2',ss1 )\n",
    "\n",
    "bfs(node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 决策树构建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "决策树：\n",
      "Type:据\"纹理\"划分,Label:未定,Samples:[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16],Children:['据\"根蒂\"划分[纹理=清晰]', '据\"触感\"划分[纹理=稍糊]', 'Leaf[纹理=模糊]'] \n",
      "\tType:据\"根蒂\"划分,Label:未定,Samples:[0, 1, 2, 3, 4, 5, 7, 9, 14],Children:['Leaf[根蒂=蜷缩]', '据\"色泽\"划分[根蒂=稍蜷]', 'Leaf[根蒂=硬挺]'] \n",
      "\t\tType:Leaf,Label:好瓜,Samples:[0, 1, 2, 3, 4],Children:[] \n",
      "\t\tType:据\"色泽\"划分,Label:未定,Samples:[5, 7, 14],Children:['Leaf[色泽=乌黑]', 'Leaf[色泽=青绿]'] \n",
      "\t\t\tType:Leaf,Label:好瓜,Samples:[7, 14],Children:[] \n",
      "\t\t\tType:Leaf,Label:好瓜,Samples:[5],Children:[] \n",
      "\t\tType:Leaf,Label:坏瓜,Samples:[9],Children:[] \n",
      "\tType:据\"触感\"划分,Label:未定,Samples:[6, 8, 12, 13, 16],Children:['Leaf[触感=硬滑]', 'Leaf[触感=软粘]'] \n",
      "\t\tType:Leaf,Label:坏瓜,Samples:[8, 12, 13, 16],Children:[] \n",
      "\t\tType:Leaf,Label:好瓜,Samples:[6],Children:[] \n",
      "\tType:Leaf,Label:坏瓜,Samples:[10, 11, 15],Children:[] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def createDT(dataFrame,depth):\n",
    "    \"\"\"\n",
    "    功能：根据有标记数据集dataFrame，构建深度为depth的决策树\n",
    "    输入：训练集 𝐷 = dataFrame ，属性名为dataframe的第0行\n",
    "          树的深度为depth，默认值为3\n",
    "    输出：一棵以嵌套字典表示的决策树  \n",
    "\n",
    "    \"\"\"\n",
    "    # 生成结点\n",
    "    node = Node()\n",
    "         \n",
    "    if len(dataFrame.iloc[:,-1].value_counts()) == 1:\n",
    "        #若D 中样本全属于同一类别，则将node标记为C类叶结点\n",
    "        node.setType = 'Leaf'\n",
    "        node.setLabel = dataFrame.iloc[0,-1]\n",
    "        node.setSamples = dataFrame    \n",
    "        return node\n",
    "   \n",
    "    \n",
    "    if len(dataFrame.iloc[:,:-1]) == 0 :\n",
    "        # A = 空集 :\n",
    "        # 将 node 标记为叶结点，其类别标记为 D 中样本数最多的类；\n",
    "        # 注意，因为可能存在未知因素，会存在A上取值相同，但分类不同的示例。        \n",
    "        tempdict = {}\n",
    "        tempdict.update(dataFrame.iloc[:,-1].value_counts())  \n",
    "        if tempdict:\n",
    "            label = sorted(tempdict,key =lambda item:item[1],reverse=True)[0]  \n",
    "        else:\n",
    "            label = ''\n",
    "        node.setType = 'Leaf' \n",
    "        node.setLabel = label\n",
    "        node.setSamples = dataFrame\n",
    "        return node\n",
    "    \n",
    "    valueIsUnique = False\n",
    "   \n",
    "    for feature in dataFrame.columns[:-1]:    \n",
    "        if len(dataFrame[feature].value_counts()) > 1:\n",
    "            # 属性集任一个属性的取值不唯一，就跳出\n",
    "            break\n",
    "        valueIsUnique = True\n",
    "    if valueIsUnique :\n",
    "        # D 中样本在 A 上取值相同 :\n",
    "        # 将 node 标记为叶结点，其类别标记为 D 中样本数最多的类；\n",
    "        # 注意，因为可能存在未知因素，会存在A上取值相同，但分类不同的示例。        \n",
    "        tempdict = {}\n",
    "        tempdict.update(dataFrame.iloc[:,-1].value_counts())        \n",
    "        label = sorted(tempdict,key =lambda item:item[1],reverse=True)[0]        \n",
    "        node.setType = 'Leaf' \n",
    "        node.setLabel = label\n",
    "        node.setSamples = dataFrame      \n",
    "        return node\n",
    "  \n",
    "    #从 A 中选择最优划分属性  𝑎∗ \n",
    "    \n",
    "    aFeature = getBestDivideFeature(dataFrame)[0]    \n",
    "    #print(\"  使用{}作为划分依据\".format(aFeature))\n",
    "    node.setType = \"据\\\"{}\\\"划分\".format(aFeature)\n",
    "    node.setLabel = '未定'\n",
    "    node.setSamples = dataFrame\n",
    "    \n",
    "    dict = {}\n",
    "    dict.update(dataFrame[aFeature].value_counts())\n",
    "    for colValue in dict.keys():\n",
    "        keyname = aFeature+'='+colValue\n",
    "        #对𝑎∗ 的每一个值  𝑎𝑣∗ ，为node生成一个分支 \n",
    "        aBranchNode = Node()                      \n",
    "        #令 𝐷𝑣 表示D中在 𝑎∗ 上取值为 𝑎𝑣∗ 的样本子集；\n",
    "        dv = dataFrame[dataFrame[aFeature]==colValue]         \n",
    "        if  dv.empty:\n",
    "            # 若dv为空,将分支结点标记为叶节点，其类别标记为D中样本最多的类；\n",
    "            tempdict = {}\n",
    "            tempdict.update(dataFrame.iloc[:,-1].value_counts())        \n",
    "            label = sorted(tempdict,key =lambda item:item[1],reverse=True)[0]              \n",
    "            aBranchNode.setType = 'Leaf' \n",
    "            aBranchNode.setLabel = label\n",
    "            aBranchNode.setSamples = dv\n",
    "            # 将aBranchNode列为node的子节点           \n",
    "            node.addChildren(keyname,aBranchNode)              \n",
    "        else:    \n",
    "            # 去除数据集Dv 中aFeature列后的样本\n",
    "            subDv = dv.drop([aFeature],axis =1)            \n",
    "            if depth == 0:\n",
    "                #若当前树的深度已经达到要求，则将当前分支节点的其类别标记为D中样本最多的类\n",
    "                tempdict = {}\n",
    "                tempdict.update(subDv.iloc[:,-1].value_counts())        \n",
    "                label = sorted(tempdict,key =lambda item:item[1],reverse=True)[0]              \n",
    "                aBranchNode.setType = 'Leaf' \n",
    "                aBranchNode.setLabel = label    \n",
    "                aBranchNode.setSamples = subDv\n",
    "                # 将aBranchNode列为node的子节点                \n",
    "                node.addChildren(keyname,aBranchNode)     \n",
    "                continue\n",
    "            # 以 createDT(subDv)  为分支结点；\n",
    "            node.addChildren(keyname,createDT(subDv,depth-1))\n",
    "    return node\n",
    "    \n",
    "#dataframe = pd.read_csv(\"data/vote/votesimple.txt\",header=0,sep=',')    \n",
    "df = pd.read_csv(\"data/maloon/maloon2.txt\",header=0,sep=',')\n",
    "d = df.iloc[:,1:]\n",
    "dtree = createDT(d,depth = 5)\n",
    "print('决策树：')\n",
    "bfs(dtree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\pythonspace\\anaconda3\\lib\\site-packages\\sklearn\\__init__.py\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "print(sklearn.__file__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用sklearn中的决策树分类器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
