{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>å®éªŒ3 å†³ç­–æ ‘ç®—æ³•å®è·µ </center>\n",
    "\n",
    "# ä¸€ã€å®éªŒç›®çš„\n",
    "\n",
    "é€šè¿‡å®éªŒï¼Œè¾¾åˆ°ä»¥ä¸‹ç›®çš„ï¼š\n",
    "\n",
    "- ä½¿å­¦ç”ŸåŠ æ·±å¯¹æœºå™¨å­¦ä¹ è¿‡ç¨‹çš„ç†è§£ï¼›\n",
    "- ä½¿å­¦ç”Ÿç†è§£ä¿¡æ¯ç†µä¸ä¿¡æ¯å¢ç›Šçš„è®¡ç®—æ–¹æ³•ï¼›\n",
    "- ä½¿å­¦ç”ŸæŒæ¡å†³ç­–æ ‘çš„æ„å»ºæ–¹æ³•å’Œç¨‹åºå®ç°ï¼›\n",
    "- ä½¿å­¦ç”Ÿèƒ½å¤Ÿç†Ÿç»ƒåº”ç”¨sklearnåº“å®ç°åŸºäºå†³ç­–æ ‘æ–¹æ³•çš„åˆ†ç±»é¢„æµ‹ã€‚\n",
    "\n",
    "# äºŒã€å®éªŒå†…å®¹\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## å†³ç­–æ ‘ï¼ˆDecision Treeï¼‰\n",
    "\n",
    "å†³ç­–æ ‘æ˜¯ä¸€ç§å¸¸è§çš„æœºå™¨å­¦ä¹ æ–¹æ³•ã€‚å¸¸ç”¨äºåˆ†ç±»ä»»åŠ¡ã€‚\n",
    "\n",
    "å†³ç­–æ ‘ï¼Œé¡¾åæ€ä¹‰ï¼Œæ˜¯åŸºäºæ ‘ç»“æ„æ¥è¿›è¡Œå†³ç­–çš„ï¼Œè¿™æ˜¯äººç±»åœ¨é¢ä¸´å†³ç­–é—®é¢˜æ—¶çš„ä¸€ç§å¾ˆè‡ªç„¶çš„å¤„ç†æœºåˆ¶ã€‚\n",
    "\n",
    "\n",
    "## åŸºæœ¬æµç¨‹\n",
    "\n",
    "å†³ç­–æ ‘çš„ä¸»è¦ä¼˜åŠ¿åœ¨äºå†³ç­–è¿‡ç¨‹å¾ˆå®¹æ˜“ç†è§£ã€‚åˆ©ç”¨å†³ç­–æ ‘å½¢æˆçš„åˆ¤æ–­è¿‡ç¨‹ï¼ŒåŒå¯Œæœ‰ç»éªŒçš„é¢†åŸŸä¸“å®¶å‡ ä¹å®ç°ç›¸åŒçš„ã€‚\n",
    "\n",
    "ä¸‹é¢æˆ‘ä»¬åˆ†æä¸€ä¸‹å†³ç­–æ ‘çš„åŸºæœ¬å¤„ç†æµç¨‹ã€‚\n",
    "\n",
    "ä»¥äºŒåˆ†ç±»ä»»åŠ¡ä¸ºä¾‹ï¼Œæˆ‘ä»¬å¸Œæœ›ä»ç»™å®šè®­ç»ƒæ•°æ®é›†å­¦å¾—ä¸€ä¸ªæ¨¡å‹ï¼Œç”¨äºå¯¹æ–°ç¤ºä¾‹è¿›è¡Œåˆ†ç±»ï¼Œè¿™ä¸ªå¯¹æ ·æœ¬è¿›è¡Œåˆ†ç±»çš„ä»»åŠ¡ï¼Œå¯ä»¥çœ‹ä½œå¯¹â€œå½“å‰æ ·æœ¬å±äºæ­£ç±»ä¹ˆï¼Ÿâ€è¿™ä¸ªé—®é¢˜çš„â€œå†³ç­–â€æˆ–â€œåˆ¤å®šâ€è¿‡ç¨‹ã€‚\n",
    "\n",
    "![å†³ç­–æ ‘ç¤ºä¾‹3](images\\dt\\è¥¿ç“œé—®é¢˜å†³ç­–æ ‘.png)\n",
    "\n",
    "- å†³ç­–è¿‡ç¨‹çš„æœ€ç»ˆç»“è®ºï¼ˆæ ‘çš„å¶å­ï¼‰ï¼Œå¯¹åº”äº†æˆ‘ä»¬å¸Œæœ›çš„åˆ¤å®šç»“æœï¼›\n",
    "\n",
    "- å†³ç­–è¿‡ç¨‹ä¸­æå‡ºçš„æ¯ä¸ªåˆ¤å®šé—®é¢˜ï¼Œéƒ½æ˜¯å¯¹æŸä¸ªå±æ€§çš„â€œæµ‹è¯•â€ï¼›\n",
    "\n",
    "- æ¯ä¸ªæµ‹è¯•çš„ç»“æœï¼Œè¦ä¹ˆå¯¼å‡ºæœ€ç»ˆç»“è®ºï¼Œè¦ä¹ˆå¯¼å‡ºè¿›ä¸€æ­¥çš„åˆ¤å®šé—®é¢˜ï¼Œå…¶è€ƒè™‘èŒƒå›´æ˜¯åœ¨ä¸Šä¸€æ¬¡å†³ç­–ç»“æœçš„é™å®šèŒƒå›´ä¹‹å†…ï¼›\n",
    "\n",
    "ä¸€èˆ¬åœ°ï¼Œä¸€é¢—å†³ç­–æ ‘ï¼ŒåŒ…å«ä¸€ä¸ªæ ¹èŠ‚ç‚¹ï¼Œè‹¥å¹²ä¸ªå†…éƒ¨ç»“ç‚¹ï¼Œå’Œè‹¥å¹²ä¸ªå¶èŠ‚ç‚¹ã€‚\n",
    "\n",
    "- å¶èŠ‚ç‚¹ï¼Œå¯¹åº”å†³ç­–ç»“æœï¼›\n",
    "\n",
    "- å…¶å®ƒèŠ‚ç‚¹ï¼Œå¯¹åº”ä¸€ä¸ªå±æ€§æµ‹è¯•ã€‚\n",
    "\n",
    "- æ¯ä¸ªèŠ‚ç‚¹ï¼ŒåŒ…å«çš„æ ·æœ¬é›†åˆï¼Œæ ¹æ®å±æ€§æµ‹è¯•çš„ç»“æœè¢«åˆ’åˆ†åˆ°å­èŠ‚ç‚¹ä¸­ï¼›\n",
    "\n",
    "- æ ¹èŠ‚ç‚¹ï¼ŒåŒ…å«æ ·æœ¬å…¨é›†ï¼›\n",
    "\n",
    "- ä»æ ¹èŠ‚ç‚¹åˆ°æ¯ä¸ªå¶èŠ‚ç‚¹çš„è·¯å¾„ï¼Œå¯¹åº”äº†ä¸€ä¸ªåˆ¤å®šæµ‹è¯•åºåˆ—ã€‚\n",
    "\n",
    "**å†³ç­–æ ‘å­¦ä¹ çš„ç›®çš„ï¼Œæ˜¯ä¸ºäº†äº§ç”Ÿä¸€æ£µæ³›åŒ–èƒ½åŠ›å¼ºçš„å†³ç­–æ ‘ï¼ŒåŸºæœ¬æµç¨‹éµå¾ªç®€å•è€Œä¸”ç›´è§‚çš„â€œåˆ†è€Œæ²»ä¹‹ï¼ˆdivide-and-conquerï¼‰â€ç­–ç•¥ã€‚**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## å†³ç­–æ ‘çš„æ„é€ \n",
    "\n",
    "å¦‚ä½•æ ¹æ®è®­ç»ƒé›†æ•°æ®ï¼Œå»ºç«‹å†³ç­–æ ‘å‘¢ï¼Ÿ\n",
    "\n",
    "ç»“åˆä¸Šé¢çš„åŸºæœ¬è¿‡ç¨‹ï¼Œæˆ‘ä»¬çŸ¥é“ï¼Œå†³ç­–æ ‘çš„æ¯ä¸ªèŠ‚ç‚¹å¯¹åº”äº†ä¸€ä¸ªå±æ€§æµ‹è¯•ï¼Œåœ¨æ•°æ®é›†ä¸­å¾€å¾€æœ‰ä¸€äº›å±æ€§æ˜¯â€œå¥½å±æ€§â€ï¼Œä½¿ç”¨å®ƒä»¬åšæµ‹è¯•ï¼Œèƒ½å¤Ÿæœ‰â€œæ­£ç¡®â€çš„åˆ†ç±»ç»“æœã€‚\n",
    "\n",
    "\n",
    "### æ„é€ å†³ç­–æ ‘çš„ä¼ªä»£ç \n",
    "\n",
    "è¾“å…¥1ï¼šè®­ç»ƒé›†$D={(x_1,y_1),(x_2,y_2),...,(x_m,y_m)}$   \n",
    "è¾“å…¥2ï¼šå±æ€§é›†$A = {a_1,a_2,...,a_d}$  \n",
    "è¿‡ç¨‹ï¼šå‡½æ•° TreeGenerate(D,A)\n",
    "\n",
    "\n",
    "ç”Ÿæˆç»“ç‚¹ï¼›  \n",
    "\n",
    "if D ä¸­æ ·æœ¬å…¨å±äºåŒä¸€ç±»åˆ«C :  \n",
    "&ensp;&ensp;&ensp;&ensp;å°†nodeæ ‡è®°ä¸ºCç±»å¶ç»“ç‚¹ï¼›  \n",
    "\n",
    "if A = ç©ºé›† or D ä¸­æ ·æœ¬åœ¨ A ä¸Šå–å€¼ç›¸åŒ :    \n",
    "&ensp;&ensp;&ensp;&ensp; å°† node æ ‡è®°ä¸ºå¶ç»“ç‚¹ï¼Œå…¶ç±»åˆ«æ ‡è®°ä¸º D ä¸­æ ·æœ¬æ•°æœ€å¤šçš„ç±»ï¼›  \n",
    "&ensp;&ensp;&ensp;&ensp; returnï¼›\n",
    "    \n",
    "ä» A ä¸­é€‰æ‹©æœ€ä¼˜åˆ’åˆ†å±æ€§ $a_*$;  \n",
    "for $a_*$ çš„æ¯ä¸€ä¸ªå€¼ $a_*^v$ :    \n",
    "&ensp;&ensp;&ensp;&ensp;ä¸ºnodeç”Ÿæˆä¸€ä¸ªåˆ†æ”¯ï¼›  \n",
    "&ensp;&ensp;&ensp;&ensp;ä»¤$D_v$è¡¨ç¤ºDä¸­åœ¨$a_*$ä¸Šå–å€¼ä¸º$a_*^v$çš„æ ·æœ¬å­é›†ï¼›  \n",
    "&ensp;&ensp;&ensp;&ensp;if $D_v$ ä¸ºç©ºï¼š  \n",
    "        &ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;å°†åˆ†æ”¯ç»“ç‚¹æ ‡è®°ä¸ºå¶èŠ‚ç‚¹ï¼Œå…¶ç±»åˆ«æ ‡è®°ä¸ºDä¸­æ ·æœ¬æœ€å¤šçš„ç±»ï¼›  \n",
    "        &ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;return    \n",
    "&ensp;&ensp;&ensp;&ensp;elseï¼š  \n",
    "        &ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;ä»¥$TreeGenerate(D_v,A \\ {a_*})$ ä¸ºåˆ†æ”¯ç»“ç‚¹ï¼›  \n",
    "   \n",
    "è¾“å‡ºï¼š ä»¥nodeä¸ºæ ¹èŠ‚ç‚¹çš„ä¸€æ£µå†³ç­–æ ‘ã€‚\n",
    "\n",
    "æ­¤æ—¶ï¼Œæˆ‘ä»¬çš„é—®é¢˜èšç„¦åˆ°äº†â€œæ•°æ®é›†ä¸Šå“ªäº›ç‰¹å¾åœ¨åˆ’åˆ†æ•°æ®åˆ†ç±»æ—¶ï¼Œèµ·å†³å®šæ€§ä½œç”¨ï¼Ÿâ€ï¼Œæ¢å¥è¯è¯´ï¼Œ**â€œå¦‚ä½•é€‰æ‹©æœ€ä¼˜åˆ’åˆ†å±æ€§ï¼Ÿâ€**\n",
    "\n",
    "### åˆ’åˆ†é€‰æ‹©\n",
    "\n",
    "ä¸ºäº†æ‰¾åˆ°æœ€å¥½çš„å†³ç­–å±æ€§ï¼Œæˆ‘ä»¬éœ€è¦è¯„ä¼°æ¯ä¸ªå±æ€§ã€‚é‚£ä¹ˆä»¥ä½•ç§æ ‡å‡†æ¥è¯„ä¼°ï¼Ÿ\n",
    "\n",
    "ä¸€èˆ¬è€Œè¨€ï¼Œéšç€åˆ’åˆ†è¿‡ç¨‹ä¸æ–­è¿›è¡Œï¼Œæˆ‘ä»¬å¸Œæœ›å†³ç­–æ ‘çš„åˆ†æ”¯ç»“ç‚¹æ‰€åŒ…å«çš„æ ·æœ¬ï¼Œå°½å¯èƒ½å±äºåŒä¸€ç±»åˆ«ï¼Œå³ç»“ç‚¹çš„â€œçº¯åº¦â€ï¼ˆpurityï¼‰è¶Šæ¥è¶Šé«˜ã€‚\n",
    "\n",
    "å¦‚æœå¯ä»¥åº¦é‡ï¼Œé‚£ä¹ˆæˆ‘ä»¬å¯ä»¥æ ¹æ®çº¯åº¦æ¥è¯„ä¼°æ¯ä¸ªå±æ€§ï¼Œæ‰¾åˆ°æœ€å¥½çš„å†³ç­–å±æ€§ã€‚\n",
    "\n",
    "å¦‚ä½•åº¦é‡æ ·æœ¬é›†åˆçš„çº¯åº¦å‘¢ï¼Ÿ\n",
    "\n",
    "### ä¿¡æ¯ç†µ\n",
    "\n",
    "â€œä¿¡æ¯ç†µâ€ï¼ˆinformation entropyï¼‰æ˜¯åº¦é‡æ ·æœ¬é›†åˆçº¯åº¦æœ€å¸¸ç”¨çš„ä¸€ç§æŒ‡æ ‡ã€‚\n",
    "\n",
    "å‡å®šå½“å‰æ ·æœ¬é›†åˆDä¸­ç¬¬kç±»æ ·æœ¬æ‰€å çš„æ¯”ä¾‹ä¸º$p_k(k = 1,2,...,|y|)$ï¼Œåˆ™$D$çš„ä¿¡æ¯ç†µå®šä¹‰ä¸ºï¼š\n",
    "\n",
    "$Ent(D) = - \\sum_{k=1}^{|y|}p_k \\log_{2}p_k$    â€”â€”å¼ï¼ˆ1ï¼‰\n",
    "\n",
    "Ent(D)çš„å€¼è¶Šå°ï¼Œåˆ™Dçš„çº¯åº¦è¶Šé«˜ã€‚ç†µåœ¨ä¿¡æ¯è®ºä¸­ä»£è¡¨éšæœºå˜é‡ä¸ç¡®å®šåº¦çš„åº¦é‡ï¼Œç†µå€¼è¶Šå¤§ï¼Œä¸ç¡®å®šæ€§è¶Šé«˜ã€‚\n",
    "\n",
    "> å¯¹ç†µçš„ç›´è§‚è§£é‡Šï¼Œå¯ä»¥å‚è€ƒhttps://blog.csdn.net/qq_39521554/article/details/79078917\n",
    "\n",
    "å‡å®šç¦»æ•£å±æ€§aæœ‰Vä¸ªå¯èƒ½çš„å–å€¼${a^1,a^2,...,a^v}$ï¼Œè‹¥ä½¿ç”¨aæ¥å¯¹æ ·æœ¬é›†Dè¿›è¡Œåˆ’åˆ†ï¼Œåˆ™ä¼šäº§ç”ŸVä¸ªåˆ†æ”¯ç»“ç‚¹ã€‚\n",
    "\n",
    "å…¶ä¸­ï¼Œç¬¬$v$ä¸ªåˆ†æ”¯ç»“ç‚¹åŒ…å«äº†Dä¸­æ‰€æœ‰åœ¨å±æ€§aä¸Šå–å€¼ä¸º$a^v$çš„æ ·æœ¬ï¼Œè®°ä¸º$D^v$ã€‚\n",
    "\n",
    "æ ¹æ®å¼ï¼ˆ1ï¼‰ï¼Œè®¡ç®—å‡º$D^v$çš„ä¿¡æ¯ç†µã€‚\n",
    "\n",
    "å³å½“å‰é›†åˆ$D^v$ï¼Œè®¾ç¬¬kç±»æ ·æœ¬æ‰€å çš„æ¯”ä¾‹ä¸º$p_k^v(k = 1,2,...,|y^v|)$\n",
    "\n",
    "$Ent(D^v) = - \\sum_{k=1}^{|y^v|}p_k^v \\log_{2}p_k^v$ \n",
    "\n",
    "\n",
    "ä¸‹é¢ç»™å‡ºè®¡ç®—$D^v$çš„é¦™å†œä¿¡æ¯ç†µçš„pythonç¨‹åºä»£ç "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å½“å‰æ•°æ®é›†çš„é¦™å†œä¿¡æ¯ç†µï¼š1.584702\n"
     ]
    }
   ],
   "source": [
    "\"\"\"è®¡ç®—é¦™å†œä¿¡æ¯ç†µçš„pythonç¨‹åºä»£ç \n",
    "\"\"\"\n",
    "from math import log\n",
    "from sklearn import neighbors,datasets\n",
    "import pandas as pd\n",
    "\n",
    "def calcShannonEnt(dataFrame):\n",
    "    \"\"\"\n",
    "    åŠŸèƒ½ï¼šæ ¹æ®åˆ†ç±»æ ‡è®°ï¼Œè®¡ç®—æŸæ•°æ®é›†çš„ä¿¡æ¯ç†µã€‚\n",
    "    è¾“å…¥ï¼šdataFrameï¼Œä½¿ç”¨pandas.seriersç±»å‹ç»™å‡ºçš„å«æœ‰æ ‡è®°çš„æ•°æ®é›†ï¼Œæ ‡è®°ä¿¡æ¯ä¸ºæœ€åä¸€åˆ—\n",
    "    è¾“å‡ºï¼šshannonEntï¼Œæ•°æ®é›†æŒ‰å½“å‰æ ‡è®°åˆ†ç±»ç»“æœçš„ä¿¡æ¯ç†µå€¼\n",
    "    \n",
    "    \"\"\"  \n",
    "    numEntries = dataFrame.shape[0] #sæ•°æ®é›†ç¤ºä¾‹æ•°\n",
    "    \n",
    "    labelCounts = {} #å®šä¹‰å­—å…¸ï¼Œé”®ä¸ºåˆ†ç±»æ ‡è®°åï¼Œå€¼ä¸ºæ ‡è®°çš„è®¡æ•°å€¼\n",
    "    labelCounts.update(dataFrame.iloc[:,-1].value_counts())#ä¸ºå­—å…¸èµ‹å€¼,è®¤ä¸ºæ•°æ®é›†æœ€åä¸€åˆ—ä¸ºlabel\n",
    "    \n",
    "    shannonEnt = 0.0  # è®¾ç½®é¦™å†œä¿¡æ¯ç†µåˆå€¼ä¸º0.0\n",
    "    for key in labelCounts:\n",
    "        # æŒ‰å…¬å¼æ±‚ä¿¡æ¯ç†µå€¼\n",
    "        prob = float(labelCounts[key])/numEntries\n",
    "        \n",
    "        shannonEnt -= prob * log(prob,2)    # æ±‚ä»¥2ä¸ºåº•çš„å¯¹æ•°ã€‚\n",
    "    return shannonEnt\n",
    "\n",
    "def calcDatingDataSetEnt():\n",
    "    dataframe = pd.read_csv(\"data\\dating\\datingTestSet.txt\",header=None,sep='\\t',names=['å¹´é£æœºé‡Œç¨‹','å‘¨å†°æ·‡æ·‹å‡æ•°','æ¸¸æˆè€—æ—¶æ¯”','å¿ƒä»ªç¨‹åº¦'])\n",
    "    entropy = calcShannonEnt(dataframe)\n",
    "    print(\"å½“å‰æ•°æ®é›†çš„é¦™å†œä¿¡æ¯ç†µï¼š%f\"  % entropy)\n",
    "\n",
    "calcDatingDataSetEnt()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä¸Šé¢çš„ä¾‹å­ä¸­è®¡ç®—å¾—åˆ°çš„ä¿¡æ¯ç†µå·®åˆ«ä¸å¤§ï¼Œæˆ‘ä»¬å†çœ‹ä¸€ä¸ªä¾‹å­ã€‚\n",
    "\n",
    "è¿™ä¸ªä¾‹å­æ˜¯ç¾å›½å¤§é€‰æŠ•ç¥¨æ•°æ®é›†ï¼ŒåŸºæœ¬æƒ…å†µå¦‚ä¸‹å›¾æ‰€ç¤ºï¼š\n",
    "\n",
    "![é€‰ä¸¾æ•°æ®ç¤ºä¾‹](images/dt/voteexample.png)\n",
    "\n",
    "è¿™ä¸ªä¾‹å­å°†è®¡ç®—ä¸€ä¸ªæŠ•ç¥¨æ•°æ®é›†çš„ç†µå€¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ä¿¡æ¯ç†µï¼š0.996566\n"
     ]
    }
   ],
   "source": [
    "def calcAllVoteFeaturesEnt():\n",
    "    dataframe = pd.read_csv(\"data/vote/VoteTraining-cn.csv\",header=0,sep=',')\n",
    "    \n",
    "    entropy = calcShannonEnt(dataframe)\n",
    "    print(\"ä¿¡æ¯ç†µï¼š%f\"  % entropy)\n",
    "\n",
    "calcAllVoteFeaturesEnt()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ä¿¡æ¯å¢ç›Š\n",
    "\n",
    "å‡å®šç¦»æ•£å±æ€§aæœ‰Vä¸ªå¯èƒ½çš„å–å€¼${a^1,a^2,...,a^v}$ï¼Œè‹¥ä½¿ç”¨aå¯¹æ ·æœ¬é›†Dè¿›è¡Œåˆ’åˆ†ï¼Œåˆ™ä¼šäº§ç”ŸVä¸ªåˆ†æ”¯ç»“ç‚¹ï¼Œå…¶ä¸­ç¬¬vä¸ªåˆ†æ”¯ç»“ç‚¹åŒ…å«äº†Dä¸­æ‰€æœ‰åœ¨å±æ€§aä¸Šå–å€¼ä¸º$a^v$çš„æ ·æœ¬ï¼Œè®°ä¸º$D^v$ã€‚\n",
    "\n",
    "æˆ‘ä»¬å¯ä»¥æ ¹æ®å¼ï¼ˆ1ï¼‰è®¡ç®—å‡º$D^v$çš„ä¿¡æ¯ç†µï¼Œå†è€ƒè™‘åˆ°ä¸åŒçš„åˆ†æ”¯ç»“ç‚¹æ‰€åŒ…å«çš„æ ·æœ¬æ•°ä¸åŒï¼Œç»™åˆ†æ”¯ç»“ç‚¹èµ‹äºˆæƒé‡$\\frac{|D^v|}{|D|}$ï¼Œå³æ ·æœ¬æ•°è¶Šå¤šçš„åˆ†æ”¯ç»ˆç‚¹çš„å½±å“è¶Šå¤§ï¼Œäºæ˜¯å¯è®¡ç®—å‡ºç”¨å±æ€§aå¯¹æ ·æœ¬é›†Dè¿›è¡Œåˆ’åˆ†æ‰€è·å¾—çš„â€œä¿¡æ¯å¢ç›Šâ€ï¼ˆinformation gain)ã€‚\n",
    "\n",
    "$Gain(D,a) = Ent(D) - \\sum_{v=1}^{V}\\frac{|D^v|}{|D|}Ent(D^v)$  â€”â€”å¼ï¼ˆ2ï¼‰\n",
    "\n",
    "ä¸€èˆ¬è€Œè¨€ï¼Œä¿¡æ¯å¢ç›Šè¶Šå¤§ï¼Œåˆ™æ„å‘³ç€ä½¿ç”¨å±æ€§aæ¥è¿›è¡Œåˆ’åˆ†æ‰€è·å¾—çš„â€œçº¯åº¦æå‡â€è¶Šå¤§ã€‚\n",
    "\n",
    "å› æ­¤ï¼Œæˆ‘ä»¬å¯ç”¨ä¿¡æ¯å¢ç›Šæ¥è¿›è¡Œå†³ç­–æ ‘çš„åˆ’åˆ†å±æ€§é€‰æ‹©ï¼Œå³åœ¨é€‰æ‹©â€œæœ€å¥½çš„â€å±æ€§è¿›è¡Œå†³ç­–ã€‚\n",
    "\n",
    "$a_* = argmax_{a \\in A}Gain(D,a)$\n",
    "\n",
    "è‘—åçš„ID3å†³ç­–æ ‘å­¦ä¹ ç®—æ³•ã€Quinlanï¼Œ1986ã€‘å°±æ˜¯ä»¥ä¿¡æ¯å¢ç›Šä¸ºå‡†åˆ™æ¥åˆ’åˆ†å±æ€§ã€‚\n",
    "\n",
    "ä¸‹é¢ç¨‹åºçš„ä¾‹å­æ˜¯ä»¥ç¾å›½å¤§é€‰çš„æŠ•ç¥¨æ•°æ®æ ·æœ¬é›†ä¸ºä¾‹ï¼Œé€‰æ‹©æœ€å¥½åˆ’åˆ†å±æ€§çš„ä»£ç ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('çº¹ç†', 0.3805918973682686)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calcInforGain(df,aFeature):\n",
    "    \"\"\"\n",
    "    åŠŸèƒ½ï¼šæŒ‰ç…§ä¸Šè¿°å…¬å¼è®¡ç®—ç”¨å±æ€§aFeatureå¯¹æ ·æœ¬é›†dataframeè¿›è¡Œåˆ’åˆ†çš„ä¿¡æ¯å¢ç›Šã€‚\n",
    "    è¾“å…¥ï¼šæ•°æ®é›†dataFrameï¼›\n",
    "          åˆ’åˆ†å±æ€§åaFeatureï¼›\n",
    "    è¾“å‡ºï¼šï¼ˆæœ€å¥½åˆ’åˆ†å±æ€§åç§°ï¼Œæœ€å¤§ä¿¡æ¯å¢ç›Šå€¼ï¼‰\n",
    "    \"\"\"\n",
    "    # ç»Ÿè®¡æ•°æ®é›†çš„æ ·æœ¬æ•°é‡\n",
    "    totalsampleCount = df.shape[0]\n",
    "    # ç»Ÿè®¡å±æ€§aå„å€¼å¯¹åº”çš„æ ·æœ¬æ•°é‡\n",
    "    sampleCounts = {} \n",
    "    sampleCounts.update(df[aFeature].value_counts())\n",
    "    #print(sampleCounts)\n",
    "    infogain = calcShannonEnt(df)\n",
    "    for key,value in sampleCounts.items():\n",
    "        subdf = df[df[aFeature] == key]\n",
    "        infogain -= subdf.shape[0]/ totalsampleCount * calcShannonEnt(subdf)\n",
    "    return infogain\n",
    "\n",
    "def getBestDivideFeature(df):    \n",
    "    featureInfoGains = {}    \n",
    "    for colname in df.columns[:-1]:\n",
    "        # å¯¹éæ ‡è®°å±æ€§ï¼Œè®¡ç®—å…¶ä¿¡æ¯å¢ç›Šï¼Œæ ‡è®°å±æ€§ä¸ºdataframeä¸­æœ€åä¸€åˆ—\n",
    "        infogain = calcInforGain(df,colname)\n",
    "        featureInfoGains[colname] = infogain\n",
    "    # å¯¹å·²è®¡ç®—å¢ç›Šçš„ç»“æœè¿›è¡Œæ’åº\n",
    "    bestFeature = sorted(featureInfoGains.items(),key =lambda item:item[1],reverse=True)[0]\n",
    "    #print(featureInfoGains)\n",
    "    return bestFeature\n",
    "\n",
    "#dataframe = pd.read_csv(\"data/vote/VoteTraining-cn.csv\",header=0,sep=',')        \n",
    "#getBestDivideFeature(dataframe)    \n",
    "dataframe = pd.read_csv(\"data/maloon/maloon2.txt\",header=0,sep=',')        \n",
    "getBestDivideFeature(dataframe.iloc[:,1:])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ ¹æ®è®¡ç®—ä¿¡æ¯å¢ç›Šï¼Œå‘ç°åœ¨æŠ•ç¥¨æ•°æ®é›†ä¸­ï¼Œâ€œåŒ»å¸ˆè´¹ç”¨å†»ç»“â€å±æ€§å¯¹æ•°æ®é›†è¿›è¡Œåˆ’åˆ†çš„ä¿¡æ¯å¢ç›Šæœ€å¤§ï¼Œäºæ˜¯æˆ‘ä»¬å°†é€‰æ‹©å®ƒä½œä¸ºåˆ’åˆ†å±æ€§ã€‚\n",
    "\n",
    "åˆ’åˆ†ç»“æœå¦‚ä¸‹ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æŒ‰\"åŒ»å¸ˆè´¹ç”¨å†»ç»“\"è¿›è¡Œåˆ’åˆ†:\n",
      "    nç±»çš„èŠ‚ç‚¹æ•°ä¸º119\n",
      "    yç±»çš„èŠ‚ç‚¹æ•°ä¸º113\n"
     ]
    }
   ],
   "source": [
    "dataframe = pd.read_csv(\"data/vote/VoteTraining-cn.csv\",header=0,sep=',')\n",
    "dict = {}\n",
    "dict.update(dataframe[\"åŒ»å¸ˆè´¹ç”¨å†»ç»“\"].value_counts())\n",
    "subDList = {}\n",
    "for colValue in dict.keys():\n",
    "    subDList[colValue] = dataframe[dataframe[\"åŒ»å¸ˆè´¹ç”¨å†»ç»“\"]==colValue]\n",
    "\n",
    "print(\"æŒ‰\\\"åŒ»å¸ˆè´¹ç”¨å†»ç»“\\\"è¿›è¡Œåˆ’åˆ†:\")\n",
    "for i in subDList.items():\n",
    "    print(\"    {}ç±»çš„èŠ‚ç‚¹æ•°ä¸º{}\".format(i[0],i[1].shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ç„¶åï¼Œå†³ç­–æ ‘å­¦ä¹ ç®—æ³•å°†å¯¹æ¯ä¸ªåˆ†æ”¯ç»“ç‚¹åšè¿›ä¸€æ­¥åˆ’åˆ†ã€‚\n",
    "\n",
    "å¦‚ä¸Šä¾‹ä¸­ï¼Œé€šè¿‡â€œåŒ»å¸ˆè´¹ç”¨å†»ç»“â€è¿›è¡Œåˆ’åˆ†åï¼Œéœ€è¦å†æ¬¡è®¡ç®—â€œæœ€å¥½åˆ’åˆ†å±æ€§â€ï¼Œå¯¹å„åˆ†æ”¯ç»“ç‚¹æ‰€å«æ•°æ®é›†è¿›è¡Œåˆ’åˆ†ã€‚\n",
    "\n",
    "### æ„å»ºå†³ç­–æ ‘çš„ç¨‹åº\n",
    "\n",
    "é€‰æ‹©æœ€ä½³å±æ€§çš„è¿‡ç¨‹ä¸€èˆ¬éœ€è¦å¤šæ¬¡ï¼Œå¯¹æ¯ä¸ªåˆ†æ”¯ç»“ç‚¹è¿›è¡Œä¸Šè¿°æ“ä½œï¼Œç›´è‡³å°†æ‰€æœ‰å±æ€§éƒ½ä½¿ç”¨å®Œæ¯•ã€‚è¿™æ ·ä¸€æ£µå†³ç­–æ ‘å°±å»ºç«‹èµ·æ¥äº†ã€‚\n",
    "\n",
    "ä½†æ˜¯ï¼Œå¤§å¤šæ•°ç”¨æˆ·ä¸éœ€è¦è¿™æ ·çš„å†³ç­–æ ‘ï¼Œè€Œæ˜¯éœ€è¦é‚£ç§åªé€šè¿‡3~5ä¸ªå±æ€§å€¼å°±èƒ½å¤Ÿè¿›è¡Œåˆ†ç±»çš„å†³ç­–æ ‘ã€‚\n",
    "\n",
    "è¿™æ—¶éœ€è¦ç”±ç”¨æˆ·äº‹å…ˆæŒ‡å®šâ€œæ ‘çš„æ·±åº¦â€è¿™ä¸ªè¶…å‚æ¥æ„å»ºå†³ç­–æ ‘ã€‚\n",
    "\n",
    "ä¸‹é¢ï¼Œæ ¹æ®ä¸Šæ–‡ä¸­æ„é€ å†³ç­–æ ‘çš„ä¼ªä»£ç ï¼Œæˆ‘ä»¬ç¼–å†™å†³ç­–æ ‘æ„å»ºå‡½æ•°ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "class Node:\n",
    "    \"\"\"å†³ç­–æ ‘ç»“ç‚¹ç±»\"\"\"\n",
    "    def __init__(self):\n",
    "        self._type = None\n",
    "        self._label = None\n",
    "        self._samples = pd.DataFrame()\n",
    "        self._children = {}        \n",
    "    \n",
    "    @property    \n",
    "    def type(self):\n",
    "        return self._type\n",
    "    \n",
    "    @type.setter\n",
    "    def setType(self,type):\n",
    "        self._type = type\n",
    "    \n",
    "    @property    \n",
    "    def label(self):\n",
    "        return self._label\n",
    "    \n",
    "    @label.setter\n",
    "    def setLabel(self,label):\n",
    "        self._label = label\n",
    "        \n",
    "    @property\n",
    "    def samples(self):\n",
    "        return self._samples\n",
    "    \n",
    "    @samples.setter\n",
    "    def setSamples(self,samples):\n",
    "        if isinstance(samples, pd.DataFrame):\n",
    "            self._samples = samples\n",
    "    \n",
    "    @property    \n",
    "    def children(self):\n",
    "        return self._children\n",
    "    \n",
    "\n",
    "    def addChildren(self,key,children):\n",
    "        self._children[key] = children\n",
    "\n",
    "    def getChildrenTypeList(self):\n",
    "        cl = []\n",
    "        for k,v in self._children.items():\n",
    "            cl.append(v.type + '['+k+']')\n",
    "        return cl\n",
    "    \n",
    "    def __str__(self):        \n",
    "        return \"Type:{},Label:{},Samples:{},Children:{} \".format(\n",
    "                self._type,self._label,\n",
    "                self._samples.index.tolist(),\n",
    "                self.getChildrenTypeList())\n",
    "def bfs(rootNode,depth = 0):\n",
    "    print(\"{}{}\".format('\\t'*depth,rootNode))\n",
    "    #print(\"Type:{},Label:{},Samples:{}\".format(rootNode.type,rootNode.label,rootNode.samples.index.tolist()))\n",
    "    for k,v in rootNode.children.items():\n",
    "        bfs(v,depth + 1)\n",
    "    return depth\n",
    "        \n",
    "              \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä¸‹é¢çš„ä»£ç ç”¨äºæµ‹è¯•ä¸Šè¿°ç±»å®šä¹‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type:root,Label:None,Samples:[],Children:['middle[a=1]', 'middle[a=2]'] \n",
      "Type:root,Label:None,Samples:[],Children:['middle[a=1]', 'middle[a=2]'] \n",
      "\tType:middle,Label:None,Samples:[],Children:['leaf[b=1]', 'leaf[b=2]'] \n",
      "\t\tType:leaf,Label:None,Samples:[],Children:[] \n",
      "\t\tType:leaf,Label:None,Samples:[],Children:[] \n",
      "\tType:middle,Label:None,Samples:[],Children:[] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node = Node()\n",
    "node.setType = 'root' \n",
    "child = Node()\n",
    "node.addChildren('a=1',child)\n",
    "child.setType = 'middle'\n",
    "child2 = Node()\n",
    "node.addChildren('a=2',child2)\n",
    "child2.setType = 'middle'\n",
    "ss = Node()\n",
    "ss.setType = 'leaf'\n",
    "ss1 = Node()\n",
    "ss1.setType = 'leaf'\n",
    "child.addChildren('b=1',ss)\n",
    "child.addChildren('b=2',ss1 )\n",
    "print(node)\n",
    "bfs(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def createDT(dataFrame,depth):\n",
    "    \"\"\"\n",
    "    åŠŸèƒ½ï¼šæ ¹æ®æœ‰æ ‡è®°æ•°æ®é›†dataFrameï¼Œæ„å»ºæ·±åº¦ä¸ºdepthçš„å†³ç­–æ ‘\n",
    "    è¾“å…¥ï¼šè®­ç»ƒé›† ğ· = dataFrame ï¼Œå±æ€§åä¸ºdataframeçš„ç¬¬0è¡Œ\n",
    "          æ ‘çš„æ·±åº¦ä¸ºdepthï¼Œé»˜è®¤å€¼ä¸º3\n",
    "    è¾“å‡ºï¼šä¸€æ£µä»¥åµŒå¥—å­—å…¸è¡¨ç¤ºçš„å†³ç­–æ ‘  \n",
    "\n",
    "    \"\"\"\n",
    "    # ç”Ÿæˆç»“ç‚¹\n",
    "    node = Node()\n",
    "         \n",
    "    if len(dataFrame.iloc[:,-1].value_counts()) == 1:\n",
    "        #è‹¥D ä¸­æ ·æœ¬å…¨å±äºåŒä¸€ç±»åˆ«ï¼Œåˆ™å°†nodeæ ‡è®°ä¸ºCç±»å¶ç»“ç‚¹\n",
    "        node.setType = 'Leaf'\n",
    "        node.setLabel = dataFrame.iloc[0,-1]\n",
    "        node.setSamples = dataFrame    \n",
    "        return node\n",
    "\n",
    "    if len(dataFrame.iloc[:,:-1]) == 0 :\n",
    "        # A = ç©ºé›† :\n",
    "        # å°† node æ ‡è®°ä¸ºå¶ç»“ç‚¹ï¼Œå…¶ç±»åˆ«æ ‡è®°ä¸º D ä¸­æ ·æœ¬æ•°æœ€å¤šçš„ç±»ï¼›\n",
    "        # æ³¨æ„ï¼Œå› ä¸ºå¯èƒ½å­˜åœ¨æœªçŸ¥å› ç´ ï¼Œä¼šå­˜åœ¨Aä¸Šå–å€¼ç›¸åŒï¼Œä½†åˆ†ç±»ä¸åŒçš„ç¤ºä¾‹ã€‚        \n",
    "        tempdict = {}\n",
    "        tempdict.update(dataFrame.iloc[:,-1].value_counts())  \n",
    "        if tempdict:\n",
    "            label = sorted(tempdict,key =lambda item:item[1],reverse=True)[0]  \n",
    "        else:\n",
    "            label = ''\n",
    "        node.setType = 'Leaf' \n",
    "        node.setLabel = label\n",
    "        node.setSamples = dataFrame\n",
    "        return node\n",
    "    \n",
    "    valueIsUnique = False\n",
    "   \n",
    "    for feature in dataFrame.columns[:-1]:    \n",
    "        if len(dataFrame[feature].value_counts()) > 1:\n",
    "            # å±æ€§é›†ä»»ä¸€ä¸ªå±æ€§çš„å–å€¼ä¸å”¯ä¸€ï¼Œå°±è·³å‡º\n",
    "            break\n",
    "        valueIsUnique = True\n",
    "    if valueIsUnique :\n",
    "        # D ä¸­æ ·æœ¬åœ¨ A ä¸Šå–å€¼ç›¸åŒ :\n",
    "        # å°† node æ ‡è®°ä¸ºå¶ç»“ç‚¹ï¼Œå…¶ç±»åˆ«æ ‡è®°ä¸º D ä¸­æ ·æœ¬æ•°æœ€å¤šçš„ç±»ï¼›\n",
    "        # æ³¨æ„ï¼Œå› ä¸ºå¯èƒ½å­˜åœ¨æœªçŸ¥å› ç´ ï¼Œä¼šå­˜åœ¨Aä¸Šå–å€¼ç›¸åŒï¼Œä½†åˆ†ç±»ä¸åŒçš„ç¤ºä¾‹ã€‚        \n",
    "        tempdict = {}\n",
    "        tempdict.update(dataFrame.iloc[:,-1].value_counts())        \n",
    "        label = sorted(tempdict,key =lambda item:item[1],reverse=True)[0]        \n",
    "        node.setType = 'Leaf' \n",
    "        node.setLabel = label\n",
    "        node.setSamples = dataFrame      \n",
    "        return node\n",
    "  \n",
    "    #ä» A ä¸­é€‰æ‹©æœ€ä¼˜åˆ’åˆ†å±æ€§  ğ‘âˆ— \n",
    "    \n",
    "    aFeature = getBestDivideFeature(dataFrame)[0]    \n",
    "    #print(\"  ä½¿ç”¨{}ä½œä¸ºåˆ’åˆ†ä¾æ®\".format(aFeature))\n",
    "    node.setType = \"æ®\\\"{}\\\"åˆ’åˆ†\".format(aFeature)\n",
    "    node.setLabel = 'æœªå®š'\n",
    "    node.setSamples = dataFrame\n",
    "    \n",
    "    dict = {}\n",
    "    dict.update(dataFrame[aFeature].value_counts())\n",
    "    #print(\"dictå†…å®¹ï¼š{}\".format(dict))\n",
    "    for colValue in dict.keys():\n",
    "        keyname = aFeature+'='+colValue\n",
    "        #å¯¹ğ‘âˆ— çš„æ¯ä¸€ä¸ªå€¼  ğ‘ğ‘£âˆ— ï¼Œä¸ºnodeç”Ÿæˆä¸€ä¸ªåˆ†æ”¯ \n",
    "        aBranchNode = Node()                      \n",
    "        #ä»¤ ğ·ğ‘£ è¡¨ç¤ºDä¸­åœ¨ ğ‘âˆ— ä¸Šå–å€¼ä¸º ğ‘ğ‘£âˆ— çš„æ ·æœ¬å­é›†ï¼›\n",
    "        dv = dataFrame[dataFrame[aFeature]==colValue]         \n",
    "        if  dv.empty:\n",
    "            # è‹¥dvä¸ºç©º,å°†åˆ†æ”¯ç»“ç‚¹æ ‡è®°ä¸ºå¶èŠ‚ç‚¹ï¼Œå…¶ç±»åˆ«æ ‡è®°ä¸ºDä¸­æ ·æœ¬æœ€å¤šçš„ç±»ï¼›\n",
    "            tempdict = {}\n",
    "            tempdict.update(dataFrame.iloc[:,-1].value_counts())        \n",
    "            label = sorted(tempdict,key =lambda item:item[1],reverse=True)[0]              \n",
    "            aBranchNode.setType = 'Leaf' \n",
    "            aBranchNode.setLabel = label\n",
    "            aBranchNode.setSamples = dv\n",
    "            # å°†aBranchNodeåˆ—ä¸ºnodeçš„å­èŠ‚ç‚¹           \n",
    "            node.addChildren(keyname,aBranchNode)              \n",
    "        else:    \n",
    "            # å»é™¤æ•°æ®é›†Dv ä¸­aFeatureåˆ—åçš„æ ·æœ¬\n",
    "            subDv = dv.drop([aFeature],axis =1)            \n",
    "            if depth == 0:\n",
    "                #è‹¥å½“å‰æ ‘çš„æ·±åº¦å·²ç»è¾¾åˆ°è¦æ±‚ï¼Œåˆ™å°†å½“å‰åˆ†æ”¯èŠ‚ç‚¹çš„å…¶ç±»åˆ«æ ‡è®°ä¸ºDä¸­æ ·æœ¬æœ€å¤šçš„ç±»\n",
    "                tempdict = {}\n",
    "                tempdict.update(subDv.iloc[:,-1].value_counts())        \n",
    "                label = sorted(tempdict,key =lambda item:item[1],reverse=True)[0]              \n",
    "                aBranchNode.setType = 'Leaf' \n",
    "                aBranchNode.setLabel = label    \n",
    "                aBranchNode.setSamples = subDv\n",
    "                # å°†aBranchNodeåˆ—ä¸ºnodeçš„å­èŠ‚ç‚¹                \n",
    "                node.addChildren(keyname,aBranchNode)     \n",
    "                continue\n",
    "            # ä»¥ createDT(subDv)  ä¸ºåˆ†æ”¯ç»“ç‚¹ï¼›\n",
    "            node.addChildren(keyname,createDT(subDv,depth-1))\n",
    "    return node\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä¸‹é¢æˆ‘ä»¬ä»¥è¥¿ç“œæ•°æ®é›†è¿›è¡Œæµ‹è¯•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#dataframe = pd.read_csv(\"data/vote/votesimple.txt\",header=0,sep=',')    \n",
    "df = pd.read_csv(\"data1/maloon/maloon2.txt\",header=0,sep=',')\n",
    "d = df.iloc[:,1:]\n",
    "dtree = createDT(d,depth = 5)\n",
    "print('å†³ç­–æ ‘ï¼š')\n",
    "bfs(dtree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sklearnåº“å†³ç­–æ ‘åˆ†ç±»å™¨åº”ç”¨\n",
    "\n",
    "ä¸Šé¢çš„ç¨‹åºæ˜¯æ„å»ºå†³ç­–æ ‘çš„ç¤ºä¾‹ã€‚åœ¨å®é™…åº”ç”¨ä¸­ï¼Œæˆ‘ä»¬å¾€å¾€ä½¿ç”¨è¾ƒä¸ºæˆç†Ÿçš„ç¬¬ä¸‰æ–¹å·¥å…·sklearnã€‚\n",
    "\n",
    "ä¸‹é¢çš„ç¤ºä¾‹ä¸­ï¼Œä½¿ç”¨sklearn.tree ä¸­çš„DecisionTreeClassifierå¯¹æŠ•ç¥¨æ•°æ®è¿›è¡Œé¢„æµ‹ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "democrat\n",
      "democrat\n",
      "democrat\n",
      "democrat\n",
      "democrat\n",
      "republican\n",
      "republican\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "def decisionTree(list):\n",
    "    dataframe = pd.read_csv(\"data/vote/VoteTraining-cn.csv\",header=0,sep=',')\n",
    "    #data.describe()\n",
    "    X = dataframe.iloc[:,:-1] #å­˜æ”¾è®­ç»ƒæ ·æœ¬ä¸­æ— æ ‡è®°çš„æ•°æ®\n",
    "    X1 = pd.DataFrame() # sklearnçš„ç®—æ³•åˆ†ç±»å™¨å¤§å¤šåªå¤„ç†æ•°å€¼å‹çŸ©é˜µï¼ŒX1å°†å­˜æ”¾æ•°å€¼åŒ–çš„æ ·æœ¬\n",
    "    for column in X.columns:\n",
    "        X1[column] = X[column].apply(lambda x:1 if x=='y' else 2)\n",
    "        \n",
    "    y = dataframe.iloc[:,-1] # å­˜æ”¾æ ‡è®°    \n",
    "    y1 = y.apply(lambda x:1 if x == \"republican\" else 2) # å¯¹æ ‡è®°è¿›è¡Œæ•°å€¼åŒ–\n",
    "        \n",
    "    # ä½¿ç”¨å†³ç­–æ ‘æ¨¡å‹å¯¹X,yè¿›è¡Œæ‹Ÿåˆï¼Œå³ç”Ÿæˆå†³ç­–æ ‘åˆ†ç±»å™¨\n",
    "    clf = DecisionTreeClassifier(max_depth=3)\n",
    "    clf.fit(X1, y1)\n",
    "    # å¯¹è¾“å…¥çš„listæŒ‰ä¸Šé¢ç”Ÿæˆçš„å†³ç­–æ ‘åˆ†ç±»å™¨è¿›è¡Œæ‰¹é‡é¢„æµ‹\n",
    "    predict = clf.predict([list])     \n",
    "    return predict[0]\n",
    "\n",
    "def predict():\n",
    "    dataframe = pd.read_csv(\"data/vote/Vote.csv\",header=None,sep=',')    \n",
    "    for index,row in dataframe.iterrows():\n",
    "        #print(row.tolist()[:-1])\n",
    "        row = row.apply(lambda x:1 if x=='y' else 2)\n",
    "        result = decisionTree(row.tolist()[:-1])\n",
    "        if result == 1:\n",
    "            print(\"republican\")\n",
    "        else:\n",
    "            print(\"democrat\")\n",
    "        \n",
    "predict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ç†è§£sklearnçš„å†³ç­–æ ‘åˆ†ç±»å™¨\n",
    "\n",
    "ä¸‹é¢æˆ‘ä»¬é€šè¿‡åˆ†æç¨‹åºæ¥ç†è§£ä¸Šè¿°å†³ç­–æ ‘çš„åŸºæœ¬æƒ…å†µï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_nodes=11\n",
      "children_left=[ 1  2  3 -1 -1 -1  7 -1  9 -1 -1]\n",
      "children_right=[ 6  5  4 -1 -1 -1  8 -1 10 -1 -1]\n",
      "feature=[ 3 10  8 -2 -2 -2  2 -2  5 -2 -2]\n",
      "threshold=[ 1.5  1.5  1.5 -2.  -2.  -2.   1.5 -2.   1.5 -2.  -2. ]\n",
      "The binary tree structure has 11 nodes and has the following tree structure:\n",
      "node=0 test node: go to node 1 if X[:, 3] <= 1.5 else to node 6.\n",
      "\tnode=1 test node: go to node 2 if X[:, 10] <= 1.5 else to node 5.\n",
      "\t\tnode=2 test node: go to node 3 if X[:, 8] <= 1.5 else to node 4.\n",
      "\t\t\tnode=3 leaf node.\n",
      "\t\t\tnode=4 leaf node.\n",
      "\t\tnode=5 leaf node.\n",
      "\tnode=6 test node: go to node 7 if X[:, 2] <= 1.5 else to node 8.\n",
      "\t\tnode=7 leaf node.\n",
      "\t\tnode=8 test node: go to node 9 if X[:, 5] <= 1.5 else to node 10.\n",
      "\t\t\tnode=9 leaf node.\n",
      "\t\t\tnode=10 leaf node.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "dataframe = pd.read_csv(\"data/vote/VoteTraining-cn.csv\",header=0,sep=',')\n",
    "#data.describe()\n",
    "X = dataframe.iloc[:,:-1] #å­˜æ”¾è®­ç»ƒæ ·æœ¬ä¸­æ— æ ‡è®°çš„æ•°æ®\n",
    "X1 = pd.DataFrame() # sklearnçš„ç®—æ³•åˆ†ç±»å™¨å¤§å¤šåªå¤„ç†æ•°å€¼å‹çŸ©é˜µï¼ŒX1å°†å­˜æ”¾æ•°å€¼åŒ–çš„æ ·æœ¬\n",
    "for column in X.columns:\n",
    "    X1[column] = X[column].apply(lambda x:1 if x=='y' else 2)\n",
    "y = dataframe.iloc[:,-1] # å­˜æ”¾æ ‡è®°    \n",
    "y1 = y.apply(lambda x:1 if x == \"republican\" else 2) # å¯¹æ ‡è®°è¿›è¡Œæ•°å€¼åŒ–\n",
    "\n",
    "# ä½¿ç”¨å†³ç­–æ ‘æ¨¡å‹å¯¹X,yè¿›è¡Œæ‹Ÿåˆï¼Œå³ç”Ÿæˆå†³ç­–æ ‘åˆ†ç±»å™¨\n",
    "clf = DecisionTreeClassifier(max_depth=3)\n",
    "clf.fit(X1, y1)\n",
    "\n",
    "n_nodes = clf.tree_.node_count\n",
    "children_left = clf.tree_.children_left\n",
    "children_right = clf.tree_.children_right\n",
    "feature = clf.tree_.feature\n",
    "threshold = clf.tree_.threshold\n",
    "    \n",
    "print(\"n_nodes={}\".format(n_nodes))\n",
    "print(\"children_left={}\".format(children_left))\n",
    "print(\"children_right={}\".format(children_right))\n",
    "print(\"feature={}\".format(feature))\n",
    "print(\"threshold={}\".format(threshold))\n",
    "\n",
    "# The tree structure can be traversed to compute various properties such\n",
    "# as the depth of each node and whether or not it is a leaf.\n",
    "node_depth = np.zeros(shape=n_nodes, dtype=np.int64)\n",
    "is_leaves = np.zeros(shape=n_nodes, dtype=bool)\n",
    "stack = [(0, -1)]  # seed is the root node id and its parent depth\n",
    "while len(stack) > 0:\n",
    "    node_id, parent_depth = stack.pop()\n",
    "    node_depth[node_id] = parent_depth + 1\n",
    "\n",
    "    # If we have a test node\n",
    "    if (children_left[node_id] != children_right[node_id]):\n",
    "        stack.append((children_left[node_id], parent_depth + 1))\n",
    "        stack.append((children_right[node_id], parent_depth + 1))\n",
    "    else:\n",
    "        is_leaves[node_id] = True\n",
    "\n",
    "print(\"The binary tree structure has %s nodes and has \"\n",
    "      \"the following tree structure:\"\n",
    "      % n_nodes)\n",
    "for i in range(n_nodes):\n",
    "    if is_leaves[i]:\n",
    "        print(\"%snode=%s leaf node.\" % (node_depth[i] * \"\\t\", i))\n",
    "    else:\n",
    "        print(\"%snode=%s test node: go to node %s if X[:, %s] <= %s else to \"\n",
    "              \"node %s.\"\n",
    "              % (node_depth[i] * \"\\t\",\n",
    "                 i,\n",
    "                 children_left[i],\n",
    "                 feature[i],\n",
    "                 threshold[i],\n",
    "                 children_right[i],\n",
    "                 ))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ä¸‰ã€å®éªŒè¦æ±‚\n",
    "\n",
    "1. å­¦ç”Ÿåº”å½“èƒ½å¤Ÿåœ¨æ•™å¸ˆçš„æŒ‡å¯¼ä¸‹ç†è§£ä¸Šè¿°å¤„ç†è¿‡ç¨‹å’Œpythonä»£ç å®ç°ï¼›\n",
    "2. å‚è€ƒå®éªŒå†…å®¹å®Œæˆä¸€ä¸ªè‡ªé€‰æ–°æ•°æ®é›†çš„åˆ†ç±»é¢„æµ‹ï¼›\n",
    "3. æ ¹æ®å®éªŒè¿‡ç¨‹ä¸ç»“æœç¼–å†™å®éªŒæŠ¥å‘Šã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "312.77px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
